#!/usr/bin/env python3
"""
MCP Server for Audio Semantic Search for Journalists
Exposes audio dataset search functionality as MCP tools for Claude Desktop
"""

import asyncio
import logging
import os
from pathlib import Path
import platform
import shutil
import sys
from typing import Any

# Add src directory to path for imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from mcp.server import NotificationOptions, Server
from mcp.server.models import InitializationOptions
import mcp.types as types
from mcp.types import (
    Tool,
)

# Import our audio search components
from query_client import AudioDatasetClient


class AudioSearchMCPServer:
    def __init__(self):
        self.server = Server("audio-search")
        self.client: AudioDatasetClient | None = None
        self.dataset_dir = None
        self.logger = logging.getLogger(__name__)

        # Background processing state
        self.background_tasks = {}
        self.processing_status = {}

        # Register handlers
        self._register_handlers()

    def _register_handlers(self):
        """Register all MCP handlers"""

        @self.server.list_tools()
        async def handle_list_tools() -> list[Tool]:
            """List available tools"""
            return [
                Tool(
                    name="semantic_search",
                    description="Search audio segments using semantic text search",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "Search query text (e.g., 'econom√≠a pol√≠tica', 'crisis econ√≥mica')"
                            },
                            "k": {
                                "type": "integer",
                                "description": "Number of results to return (default: 5)",
                                "default": 5
                            }
                        },
                        "required": ["query"]
                    }
                ),
                Tool(
                    name="audio_search",
                    description="Search audio segments using audio keyword/class search",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "Audio-related query (e.g., 'applause', 'music', 'speech')"
                            },
                            "k": {
                                "type": "integer",
                                "description": "Number of results to return (default: 5)",
                                "default": 5
                            }
                        },
                        "required": ["query"]
                    }
                ),
                Tool(
                    name="sentiment_search",
                    description="Search audio segments by sentiment/emotion",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "sentiment": {
                                "type": "string",
                                "description": "Sentiment to search for (positive, negative, neutral, joy, anger, fear, etc.)"
                            },
                            "k": {
                                "type": "integer",
                                "description": "Number of results to return (default: 5)",
                                "default": 5
                            }
                        },
                        "required": ["sentiment"]
                    }
                ),
                Tool(
                    name="hybrid_search",
                    description="Combined text and audio search with weighted scoring",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "Search query for both text and audio content"
                            },
                            "k": {
                                "type": "integer",
                                "description": "Number of results to return (default: 5)",
                                "default": 5
                            },
                            "text_weight": {
                                "type": "number",
                                "description": "Weight for text search (0.0-1.0, default: 0.7)",
                                "default": 0.7
                            }
                        },
                        "required": ["query"]
                    }
                ),
                Tool(
                    name="mood_search",
                    description="Search with text query filtered by sentiment",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "Text search query"
                            },
                            "sentiment": {
                                "type": "string",
                                "description": "Sentiment filter (positive, negative, neutral, etc.)"
                            },
                            "k": {
                                "type": "integer",
                                "description": "Number of results to return (default: 5)",
                                "default": 5
                            }
                        },
                        "required": ["query", "sentiment"]
                    }
                ),
                Tool(
                    name="browse_dataset",
                    description="Browse random segments from the dataset",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "count": {
                                "type": "integer",
                                "description": "Number of segments to browse (default: 10)",
                                "default": 10
                            }
                        }
                    }
                ),
                Tool(
                    name="dataset_stats",
                    description="Get statistics about the audio dataset",
                    inputSchema={
                        "type": "object",
                        "properties": {}
                    }
                ),
                Tool(
                    name="find_text",
                    description="Find segments containing specific text",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "text": {
                                "type": "string",
                                "description": "Text to search for in transcriptions"
                            }
                        },
                        "required": ["text"]
                    }
                ),
                Tool(
                    name="get_similar",
                    description="Find segments similar to a specific segment by index",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "index": {
                                "type": "integer",
                                "description": "Index of the reference segment"
                            },
                            "k": {
                                "type": "integer",
                                "description": "Number of similar segments to return (default: 5)",
                                "default": 5
                            }
                        },
                        "required": ["index"]
                    }
                ),
                Tool(
                    name="analyze_sentiment",
                    description="Analyze sentiment distribution for segments about a topic",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "topic": {
                                "type": "string",
                                "description": "Topic to analyze sentiment for"
                            }
                        },
                        "required": ["topic"]
                    }
                ),
                Tool(
                    name="list_sentiments",
                    description="List available sentiment categories",
                    inputSchema={
                        "type": "object",
                        "properties": {}
                    }
                ),
                Tool(
                    name="get_capabilities",
                    description="Get system capabilities and status",
                    inputSchema={
                        "type": "object",
                        "properties": {}
                    }
                ),
                Tool(
                    name="check_status",
                    description="Check if the MCP server is ready and fully initialized",
                    inputSchema={
                        "type": "object",
                        "properties": {}
                    }
                ),
                Tool(
                    name="play_audio_segment",
                    description="Play an audio segment from the dataset using the system's audio player",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "source_file": {
                                "type": "string",
                                "description": "Name of the source audio file (without path)"
                            },
                            "start_time": {
                                "type": "number",
                                "description": "Start time of the segment in seconds"
                            },
                            "end_time": {
                                "type": "number",
                                "description": "End time of the segment in seconds"
                            },
                            "segment_index": {
                                "type": "integer",
                                "description": "Optional: Index of segment from search results to play",
                                "minimum": 0
                            }
                        },
                        "required": ["source_file", "start_time", "end_time"]
                    }
                ),
                Tool(
                    name="process_youtube_url",
                    description="Download audio from YouTube URL and add it to the dataset pipeline (starts background processing)",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "youtube_url": {
                                "type": "string",
                                "description": "YouTube URL to download and process (e.g., https://www.youtube.com/watch?v=VIDEO_ID)"
                            },
                            "title": {
                                "type": "string",
                                "description": "Optional custom title for the downloaded audio (if not provided, will use video title)",
                                "default": ""
                            }
                        },
                        "required": ["youtube_url"]
                    }
                ),
                Tool(
                    name="check_youtube_processing",
                    description="Check the status of YouTube video processing",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "task_id": {
                                "type": "string",
                                "description": "Task ID returned from process_youtube_url",
                                "default": "latest"
                            }
                        }
                    }
                )
            ]

        @self.server.call_tool()
        async def handle_call_tool(name: str, arguments: dict[str, Any]) -> list[types.TextContent]:
            """Handle tool calls"""

            if not self.client:
                # Check if we're still initializing
                if hasattr(self, 'dataset_dir'):
                    return [types.TextContent(
                        type="text",
                        text="‚è≥ El MCP server est√° inicializ√°ndose... Por favor, espera unos segundos e intenta de nuevo.\n\nüîÑ Cargando modelos de IA y dataset de audio..."
                    )]
                return [types.TextContent(
                    type="text",
                    text="‚ùå Error: Audio search client not initialized. Please ensure the dataset is available."
                )]

            try:
                if name == "semantic_search":
                    return await self._handle_semantic_search(arguments)
                if name == "audio_search":
                    return await self._handle_audio_search(arguments)
                if name == "sentiment_search":
                    return await self._handle_sentiment_search(arguments)
                if name == "hybrid_search":
                    return await self._handle_hybrid_search(arguments)
                if name == "mood_search":
                    return await self._handle_mood_search(arguments)
                if name == "browse_dataset":
                    return await self._handle_browse_dataset(arguments)
                if name == "dataset_stats":
                    return await self._handle_dataset_stats(arguments)
                if name == "find_text":
                    return await self._handle_find_text(arguments)
                if name == "get_similar":
                    return await self._handle_get_similar(arguments)
                if name == "analyze_sentiment":
                    return await self._handle_analyze_sentiment(arguments)
                if name == "list_sentiments":
                    return await self._handle_list_sentiments(arguments)
                if name == "get_capabilities":
                    return await self._handle_get_capabilities(arguments)
                if name == "check_status":
                    return await self._handle_check_status(arguments)
                if name == "play_audio_segment":
                    return await self._handle_play_audio_segment(arguments)
                if name == "process_youtube_url":
                    return await self._handle_process_youtube_url(arguments)
                if name == "check_youtube_processing":
                    return await self._handle_check_youtube_processing(arguments)
                return [types.TextContent(
                    type="text",
                    text=f"‚ùå Unknown tool: {name}"
                )]

            except Exception as e:
                return [types.TextContent(
                    type="text",
                    text=f"‚ùå Error executing {name}: {e!s}"
                )]

    async def _handle_semantic_search(self, args: dict) -> list[types.TextContent]:
        """Handle semantic text search"""
        query = args["query"]
        k = args.get("k", 5)

        results = self.client.search_text(query, k)

        if not results:
            return [types.TextContent(
                type="text",
                text=f"‚ùå No se encontraron resultados para: '{query}'"
            )]

        response = f"üîç B√∫squeda sem√°ntica: '{query}'\n"
        response += f"‚úÖ Encontrados {len(results)} segmentos relevantes\n\n"

        for result in results:
            response += f"**Segmento {result['rank']}** (Score: {result['score']:.3f})\n"
            response += f"üìÑ Archivo: {result['source_file']}\n"
            response += f"‚è∞ Tiempo: {result['start_time']:.1f}s - {result['end_time']:.1f}s\n"
            response += f"üìù Texto: {result['text']}\n"
            if 'sentiment' in result:
                response += f"üé≠ Sentimiento: {result['sentiment']}\n"
            response += "\n---\n\n"

        return [types.TextContent(type="text", text=response)]

    async def _handle_audio_search(self, args: dict) -> list[types.TextContent]:
        """Handle audio keyword search"""
        query = args["query"]
        k = args.get("k", 5)

        results = self.client.search_audio(query, k)

        if not results:
            return [types.TextContent(
                type="text",
                text=f"‚ùå No se encontraron segmentos con audio relevante para: '{query}'"
            )]

        response = f"üéµ B√∫squeda de audio: '{query}'\n"
        response += f"‚úÖ Encontrados {len(results)} segmentos con contenido de audio relevante\n\n"

        for result in results:
            response += f"**Segmento {result['rank']}** (Score: {result['score']:.3f})\n"
            response += f"üìÑ Archivo: {result['source_file']}\n"
            response += f"‚è∞ Tiempo: {result['start_time']:.1f}s - {result['end_time']:.1f}s\n"
            response += f"üìù Texto: {result['text']}\n"
            if 'audio_class' in result:
                response += f"üéµ Clase de audio: {result['audio_class']}\n"
            response += "\n---\n\n"

        return [types.TextContent(type="text", text=response)]

    async def _handle_sentiment_search(self, args: dict) -> list[types.TextContent]:
        """Handle sentiment search"""
        sentiment = args["sentiment"]
        k = args.get("k", 5)

        if not self.client.sentiment_enabled:
            return [types.TextContent(
                type="text",
                text="‚ùå El an√°lisis de sentimientos no est√° habilitado"
            )]

        results = self.client.sentiment_search_engine.search_by_sentiment(sentiment, k)

        if not results:
            return [types.TextContent(
                type="text",
                text=f"‚ùå No se encontraron segmentos con sentimiento: '{sentiment}'"
            )]

        response = f"üé≠ B√∫squeda por sentimiento: '{sentiment}'\n"
        response += f"‚úÖ Encontrados {len(results)} segmentos\n\n"

        for result in results:
            response += f"**Segmento {result['rank']}** (Score: {result['score']:.3f})\n"
            response += f"üìÑ Archivo: {result['source_file']}\n"
            response += f"‚è∞ Tiempo: {result['start_time']:.1f}s - {result['end_time']:.1f}s\n"
            response += f"üìù Texto: {result['text']}\n"
            response += f"üé≠ Sentimiento: {result['sentiment']} (Confianza: {result.get('sentiment_confidence', 'N/A')})\n"
            response += "\n---\n\n"

        return [types.TextContent(type="text", text=response)]

    async def _handle_hybrid_search(self, args: dict) -> list[types.TextContent]:
        """Handle hybrid search"""
        query = args["query"]
        k = args.get("k", 5)
        text_weight = args.get("text_weight", 0.7)

        results = self.client.search_combined(query, k, text_weight)

        if not results:
            return [types.TextContent(
                type="text",
                text=f"‚ùå No se encontraron resultados para b√∫squeda h√≠brida: '{query}'"
            )]

        response = f"üîÑ B√∫squeda h√≠brida: '{query}'\n"
        response += f"‚öñÔ∏è Peso texto: {text_weight:.1f}, Peso audio: {1-text_weight:.1f}\n"
        response += f"‚úÖ Encontrados {len(results)} segmentos\n\n"

        for result in results:
            response += f"**Segmento {result['rank']}** (Score combinado: {result['score']:.3f})\n"
            response += f"üìä Score texto: {result.get('text_score', 0):.3f} | Score audio: {result.get('audio_score', 0):.3f}\n"
            response += f"üìÑ Archivo: {result['source_file']}\n"
            response += f"‚è∞ Tiempo: {result['start_time']:.1f}s - {result['end_time']:.1f}s\n"
            response += f"üìù Texto: {result['text']}\n"
            response += "\n---\n\n"

        return [types.TextContent(type="text", text=response)]

    async def _handle_mood_search(self, args: dict) -> list[types.TextContent]:
        """Handle mood search (text query with sentiment filter)"""
        query = args["query"]
        sentiment = args["sentiment"]
        k = args.get("k", 5)

        if not self.client.sentiment_enabled:
            return [types.TextContent(
                type="text",
                text="‚ùå El an√°lisis de sentimientos no est√° habilitado"
            )]

        results = self.client.sentiment_search_engine.search_with_sentiment_filter(
            query, sentiment, k
        )

        if not results:
            return [types.TextContent(
                type="text",
                text=f"‚ùå No se encontraron resultados para '{query}' con sentimiento '{sentiment}'"
            )]

        response = "üé≠üîç B√∫squeda con filtro de sentimiento\n"
        response += f"üìù Consulta: '{query}'\n"
        response += f"üé≠ Sentimiento: '{sentiment}'\n"
        response += f"‚úÖ Encontrados {len(results)} segmentos\n\n"

        for result in results:
            response += f"**Segmento {result['rank']}** (Score: {result['score']:.3f})\n"
            response += f"üìÑ Archivo: {result['source_file']}\n"
            response += f"‚è∞ Tiempo: {result['start_time']:.1f}s - {result['end_time']:.1f}s\n"
            response += f"üìù Texto: {result['text']}\n"
            response += f"üé≠ Sentimiento: {result['sentiment']}\n"
            response += "\n---\n\n"

        return [types.TextContent(type="text", text=response)]

    async def _handle_browse_dataset(self, args: dict) -> list[types.TextContent]:
        """Handle dataset browsing"""
        count = args.get("count", 10)

        import random
        total_segments = len(self.client.df)
        indices = random.sample(range(total_segments), min(count, total_segments))

        response = f"üìä Explorando {len(indices)} segmentos aleatorios del dataset\n"
        response += f"üìà Total de segmentos en el dataset: {total_segments}\n\n"

        for i, idx in enumerate(indices, 1):
            row = self.client.df.iloc[idx]
            response += f"**Segmento {i}** (√çndice: {idx})\n"
            response += f"üìÑ Archivo: {row['source_file']}\n"
            response += f"‚è∞ Tiempo: {row['start_time']:.1f}s - {row['end_time']:.1f}s\n"
            response += f"üìù Texto: {row['text']}\n"
            if 'sentiment' in row:
                response += f"üé≠ Sentimiento: {row['sentiment']}\n"
            response += "\n---\n\n"

        return [types.TextContent(type="text", text=response)]

    async def _handle_dataset_stats(self, args: dict) -> list[types.TextContent]:
        """Handle dataset statistics"""
        df = self.client.df

        response = "üìä Estad√≠sticas del Dataset de Audio\n"
        response += "=" * 40 + "\n\n"

        response += f"üìà **Total de segmentos:** {len(df)}\n"
        response += f"üìÅ **Archivos √∫nicos:** {df['source_file'].nunique()}\n"

        # Duraci√≥n total
        total_duration = (df['end_time'] - df['start_time']).sum()
        response += f"‚è±Ô∏è **Duraci√≥n total:** {total_duration:.1f} segundos ({total_duration/60:.1f} minutos)\n"

        # Duraci√≥n promedio de segmentos
        avg_duration = (df['end_time'] - df['start_time']).mean()
        response += f"üìä **Duraci√≥n promedio por segmento:** {avg_duration:.1f} segundos\n"

        # Estad√≠sticas de texto
        text_lengths = df['text'].str.len()
        response += f"üìù **Longitud promedio de texto:** {text_lengths.mean():.0f} caracteres\n"
        response += f"üìù **Texto m√°s corto:** {text_lengths.min()} caracteres\n"
        response += f"üìù **Texto m√°s largo:** {text_lengths.max()} caracteres\n"

        # Sentimientos si est√°n disponibles
        if 'sentiment' in df.columns:
            sentiment_counts = df['sentiment'].value_counts()
            response += "\nüé≠ **Distribuci√≥n de sentimientos:**\n"
            for sentiment, count in sentiment_counts.items():
                percentage = (count / len(df)) * 100
                response += f"  ‚Ä¢ {sentiment}: {count} ({percentage:.1f}%)\n"

        # Archivos m√°s representados
        file_counts = df['source_file'].value_counts().head(5)
        response += "\nüìÅ **Archivos con m√°s segmentos:**\n"
        for file, count in file_counts.items():
            response += f"  ‚Ä¢ {file}: {count} segmentos\n"

        return [types.TextContent(type="text", text=response)]

    async def _handle_find_text(self, args: dict) -> list[types.TextContent]:
        """Handle text finding"""
        text = args["text"]

        # Search for text in transcriptions
        matches = self.client.df[self.client.df['text'].str.contains(text, case=False, na=False)]

        if matches.empty:
            return [types.TextContent(
                type="text",
                text=f"‚ùå No se encontraron segmentos que contengan: '{text}'"
            )]

        response = f"üîç B√∫squeda de texto: '{text}'\n"
        response += f"‚úÖ Encontrados {len(matches)} segmentos\n\n"

        for idx, (_, row) in enumerate(matches.head(10).iterrows(), 1):
            response += f"**Segmento {idx}** (√çndice: {row.name})\n"
            response += f"üìÑ Archivo: {row['source_file']}\n"
            response += f"‚è∞ Tiempo: {row['start_time']:.1f}s - {row['end_time']:.1f}s\n"
            response += f"üìù Texto: {row['text']}\n"
            response += "\n---\n\n"

        if len(matches) > 10:
            response += f"... y {len(matches) - 10} segmentos m√°s\n"

        return [types.TextContent(type="text", text=response)]

    async def _handle_get_similar(self, args: dict) -> list[types.TextContent]:
        """Handle finding similar segments"""
        index = args["index"]
        k = args.get("k", 5)

        if index >= len(self.client.df) or index < 0:
            return [types.TextContent(
                type="text",
                text=f"‚ùå √çndice inv√°lido: {index}. Debe estar entre 0 y {len(self.client.df)-1}"
            )]

        reference_row = self.client.df.iloc[index]
        reference_text = reference_row['text']

        # Use semantic search with the reference text
        similar_results = self.client.search_text(reference_text, k + 1)  # +1 to exclude self

        # Filter out the reference segment itself
        similar_results = [r for r in similar_results if r.get('index', -1) != index][:k]

        response = f"üîç Segmentos similares al √≠ndice {index}\n"
        response += f"üìù **Texto de referencia:** {reference_text}\n\n"

        if not similar_results:
            response += "‚ùå No se encontraron segmentos similares\n"
        else:
            response += f"‚úÖ Encontrados {len(similar_results)} segmentos similares\n\n"

            for result in similar_results:
                response += f"**Segmento {result['rank']}** (Similitud: {result['score']:.3f})\n"
                response += f"üìÑ Archivo: {result['source_file']}\n"
                response += f"‚è∞ Tiempo: {result['start_time']:.1f}s - {result['end_time']:.1f}s\n"
                response += f"üìù Texto: {result['text']}\n"
                response += "\n---\n\n"

        return [types.TextContent(type="text", text=response)]

    async def _handle_analyze_sentiment(self, args: dict) -> list[types.TextContent]:
        """Handle sentiment analysis for a topic"""
        topic = args["topic"]

        if not self.client.sentiment_enabled:
            return [types.TextContent(
                type="text",
                text="‚ùå El an√°lisis de sentimientos no est√° habilitado"
            )]

        analysis = self.client.sentiment_search_engine.analyze_sentiment_for_topic(topic)

        if not analysis:
            return [types.TextContent(
                type="text",
                text=f"‚ùå No se encontraron segmentos relacionados con: '{topic}'"
            )]

        response = f"üé≠ An√°lisis de sentimientos para: '{topic}'\n"
        response += "=" * 50 + "\n\n"

        response += f"üìä **Total de segmentos analizados:** {analysis['total_segments']}\n\n"

        response += "üìà **Distribuci√≥n de sentimientos:**\n"
        for sentiment, data in analysis['sentiment_distribution'].items():
            count = data['count']
            percentage = data['percentage']
            response += f"  ‚Ä¢ {sentiment}: {count} segmentos ({percentage:.1f}%)\n"

        response += f"\nüéØ **Sentimiento predominante:** {analysis['dominant_sentiment']}\n"
        response += f"üìä **Score promedio:** {analysis['average_confidence']:.3f}\n\n"

        response += "üí° **Ejemplos por sentimiento:**\n"
        for sentiment, examples in analysis['examples'].items():
            response += f"\n**{sentiment.upper()}:**\n"
            for example in examples[:2]:  # Show top 2 examples
                response += f"  ‚Ä¢ {example['text'][:100]}...\n"

        return [types.TextContent(type="text", text=response)]

    async def _handle_list_sentiments(self, args: dict) -> list[types.TextContent]:
        """Handle listing available sentiments"""
        if not self.client.sentiment_enabled:
            return [types.TextContent(
                type="text",
                text="‚ùå El an√°lisis de sentimientos no est√° habilitado"
            )]

        sentiments = self.client.sentiment_search_engine.get_available_sentiments()

        response = "üé≠ Sentimientos disponibles en el dataset\n"
        response += "=" * 40 + "\n\n"

        response += "üìä **Sentimientos b√°sicos:**\n"
        basic_sentiments = ['positive', 'negative', 'neutral']
        for sentiment in basic_sentiments:
            if sentiment in sentiments:
                count = sentiments[sentiment]
                response += f"  ‚Ä¢ {sentiment}: {count} segmentos\n"

        response += "\nüé≠ **Emociones espec√≠ficas:**\n"
        emotions = ['joy', 'anger', 'fear', 'sadness', 'surprise', 'disgust']
        for emotion in emotions:
            if emotion in sentiments:
                count = sentiments[emotion]
                response += f"  ‚Ä¢ {emotion}: {count} segmentos\n"

        response += "\nüìà **Otros sentimientos detectados:**\n"
        other_sentiments = [s for s in sentiments.keys()
                          if s not in basic_sentiments + emotions]
        for sentiment in sorted(other_sentiments):
            count = sentiments[sentiment]
            response += f"  ‚Ä¢ {sentiment}: {count} segmentos\n"

        response += f"\nüìä **Total de categor√≠as:** {len(sentiments)}\n"
        total_segments = sum(sentiments.values())
        response += f"üìà **Total de segmentos con sentimiento:** {total_segments}\n"

        return [types.TextContent(type="text", text=response)]

    async def _handle_get_capabilities(self, args: dict) -> list[types.TextContent]:
        """Handle getting system capabilities"""
        response = "üîß Capacidades del Sistema de B√∫squeda de Audio\n"
        response += "=" * 50 + "\n\n"

        # Dataset info
        response += f"üìä **Dataset:** {len(self.client.df)} segmentos de audio cargados\n"
        response += f"üìÅ **Archivos:** {self.client.df['source_file'].nunique()} archivos √∫nicos\n\n"

        # Search capabilities
        response += "üîç **Capacidades de b√∫squeda:**\n"
        response += "  ‚úÖ B√∫squeda sem√°ntica de texto\n"
        response += "  ‚úÖ B√∫squeda por palabras clave de audio\n"
        response += "  ‚úÖ B√∫squeda h√≠brida (texto + audio)\n"

        if self.client.sentiment_enabled:
            response += "  ‚úÖ B√∫squeda por sentimientos\n"
            response += "  ‚úÖ An√°lisis de sentimientos por tema\n"
        else:
            response += "  ‚ùå B√∫squeda por sentimientos (no disponible)\n"

        # Models info
        response += "\nüß† **Modelos cargados:**\n"
        response += "  ‚úÖ Embeddings de texto (Sentence Transformers)\n"
        if self.client.hybrid_search_enabled:
            response += "  ‚úÖ Embeddings de audio (YAMNet)\n"
        else:
            response += "  ‚ùå Embeddings de audio (no disponible)\n"

        # Index info
        response += "\nüìö **√çndices vectoriales:**\n"
        if hasattr(self.client, 'index_manager') and self.client.index_manager:
            response += "  ‚úÖ √çndice de texto\n"
            response += "  ‚úÖ √çndice de audio\n"
        else:
            response += "  ‚ùå √çndices no cargados\n"

        # Available tools
        response += "\nüõ†Ô∏è **Herramientas MCP disponibles:**\n"
        tools = [
            "semantic_search", "audio_search", "sentiment_search",
            "hybrid_search", "mood_search", "browse_dataset",
            "dataset_stats", "find_text", "get_similar",
            "analyze_sentiment", "list_sentiments", "get_capabilities",
            "check_status", "play_audio_segment", "process_youtube_url",
            "check_youtube_processing"
        ]
        for tool in tools:
            response += f"  ‚Ä¢ {tool}\n"

        return [types.TextContent(type="text", text=response)]

    async def _handle_check_status(self, args: dict) -> list[types.TextContent]:
        """Handle status check"""
        if not self.client:
            if hasattr(self, 'dataset_dir'):
                response = "‚è≥ **Estado del MCP Server: INICIALIZ√ÅNDOSE**\n\n"
                response += "üîÑ El servidor est√° cargando los siguientes componentes:\n"
                response += "  ‚Ä¢ üß† Modelos de embeddings de texto (Sentence Transformers)\n"
                response += "  ‚Ä¢ üéµ Modelo de audio YAMNet (TensorFlow)\n"
                response += "  ‚Ä¢ üìä Dataset de audio (301 segmentos)\n"
                response += "  ‚Ä¢ üîç √çndices vectoriales FAISS\n\n"
                response += "‚è±Ô∏è **Tiempo estimado:** 30-60 segundos\n"
                response += "üí° **Consejo:** Ejecuta este comando de nuevo en unos segundos para verificar el estado."
            else:
                response = "‚ùå **Estado del MCP Server: ERROR**\n\n"
                response += "El servidor no se ha inicializado correctamente.\n"
                response += "Por favor, verifica que el dataset est√© disponible."
        else:
            df = self.client.df
            response = "‚úÖ **Estado del MCP Server: LISTO**\n\n"
            response += "üéâ Todos los componentes est√°n cargados y funcionando:\n"
            response += f"  ‚Ä¢ üìä Dataset: {len(df)} segmentos cargados\n"
            response += f"  ‚Ä¢ üìÅ Archivos: {df['source_file'].nunique()} archivos √∫nicos\n"
            response += "  ‚Ä¢ üß† Embeddings de texto: ‚úÖ Listos\n"

            if self.client.hybrid_search_enabled:
                response += "  ‚Ä¢ üéµ Embeddings de audio: ‚úÖ Listos\n"
            else:
                response += "  ‚Ä¢ üéµ Embeddings de audio: ‚ùå No disponibles\n"

            if self.client.sentiment_enabled:
                response += "  ‚Ä¢ üé≠ An√°lisis de sentimientos: ‚úÖ Listo\n"
            else:
                response += "  ‚Ä¢ üé≠ An√°lisis de sentimientos: ‚ùå No disponible\n"

            response += "\nüöÄ **El servidor est√° listo para recibir consultas de b√∫squeda.**"

        return [types.TextContent(type="text", text=response)]

    def _get_audio_player_command(self):
        """Get the appropriate audio player command for the current OS"""
        system = platform.system()

        if system == "Darwin":  # macOS
            # Try ffplay first (from ffmpeg), then fallback to afplay
            if shutil.which("ffplay"):
                return "ffplay"
            if shutil.which("afplay"):
                return "afplay"
            return None
        if system == "Windows":
            # Use Windows Media Player command line
            if shutil.which("wmplayer"):
                return "wmplayer"
            if shutil.which("ffplay"):
                return "ffplay"
            return None
        if system == "Linux":
            # Try various Linux audio players
            for player in ["ffplay", "cvlc", "aplay", "paplay", "mplayer"]:
                if shutil.which(player):
                    return player
            return None
        return None

    def _build_audio_command(self, player, audio_file, start_time, end_time):
        """Build the command to play audio segment based on the player"""
        duration = end_time - start_time

        if player == "ffplay":
            return [
                "ffplay",
                "-ss", str(start_time),
                "-t", str(duration),
                "-autoexit",
                "-nodisp",  # No video display
                audio_file
            ]
        if player == "afplay":
            # afplay doesn't support time ranges directly, so we'll play the whole file
            # and mention the time range in the response
            return ["afplay", audio_file]
        if player == "wmplayer":
            return ["wmplayer", audio_file]
        if player == "cvlc":
            return [
                "cvlc",
                "--play-and-exit",
                "--start-time", str(start_time),
                "--stop-time", str(end_time),
                audio_file
            ]
        if player in ["aplay", "paplay"]:
            # These are for raw audio, might not work with all formats
            return [player, audio_file]
        if player == "mplayer":
            return [
                "mplayer",
                "-ss", str(start_time),
                "-endpos", str(duration),
                audio_file
            ]
        return None

    async def _handle_play_audio_segment(self, args: dict) -> list[types.TextContent]:
        """Handle audio segment playback"""
        source_file = args["source_file"]
        start_time = args["start_time"]
        end_time = args["end_time"]
        segment_index = args.get("segment_index")

        try:
            # Extract just the filename if a path was provided
            source_filename = Path(source_file).name
            # Get the audio player command
            player = self._get_audio_player_command()
            if not player:
                return [types.TextContent(
                    type="text",
                    text="‚ùå No audio player found on this system. Please install ffmpeg (ffplay) or another supported audio player."
                )]

            # Find the audio file in the dataset
            audio_file_path = None

            # Look for the audio file in common locations
            possible_paths = [
                self.dataset_dir / "converted" / source_filename,
                self.dataset_dir / "audio" / source_filename,
                self.dataset_dir.parent / "data" / source_filename,
                self.dataset_dir.parent / "temp_audio" / source_filename,
            ]

            # Also try different extensions
            for base_path in possible_paths:
                if base_path.exists():
                    audio_file_path = base_path
                    break

                # Try different extensions
                for ext in [".wav", ".mp3", ".opus", ".m4a", ".flac"]:
                    alt_path = base_path.with_suffix(ext)
                    if alt_path.exists():
                        audio_file_path = alt_path
                        break

                if audio_file_path:
                    break

            if not audio_file_path:
                return [types.TextContent(
                    type="text",
                    text=f"‚ùå Audio file not found: {source_filename}\n"
                         f"Original: {source_file}\n"
                         f"Searched in: {', '.join(str(p.parent) for p in possible_paths)}\n"
                         f"Make sure the audio files are available in the dataset directory."
                )]

            # Build the playback command
            command = self._build_audio_command(player, str(audio_file_path), start_time, end_time)
            if not command:
                return [types.TextContent(
                    type="text",
                    text=f"‚ùå Could not build playback command for player: {player}"
                )]

            # Execute the command asynchronously
            process = await asyncio.create_subprocess_exec(
                *command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )

            # Don't wait for completion if it's a GUI player
            if player in ["wmplayer", "afplay"]:
                response = "üéµ **Reproduciendo segmento de audio**\n\n"
            else:
                # Wait for completion for command-line players
                stdout, stderr = await process.communicate()
                response = "üéµ **Segmento de audio reproducido**\n\n"

            response += f"üìÑ **Archivo:** {source_filename}\n"
            response += f"‚è∞ **Tiempo:** {start_time:.1f}s - {end_time:.1f}s ({end_time-start_time:.1f}s de duraci√≥n)\n"
            response += f"üîß **Reproductor:** {player}\n"
            response += f"üìÇ **Ubicaci√≥n:** {audio_file_path.parent.name}/{audio_file_path.name}\n"

            if segment_index is not None:
                response += f"üìä **√çndice del segmento:** {segment_index}\n"

            if player == "afplay":
                response += f"\n‚ö†Ô∏è **Nota:** afplay reproduce el archivo completo. El segmento espec√≠fico es de {start_time:.1f}s a {end_time:.1f}s.\n"

            response += f"\n‚úÖ Comando ejecutado: `{' '.join(command)}`"

            return [types.TextContent(type="text", text=response)]

        except Exception as e:
            return [types.TextContent(
                type="text",
                text=f"‚ùå Error al reproducir el segmento de audio: {e!s}\n"
                     f"Archivo: {source_filename}\n"
                     f"Original: {source_file}\n"
                     f"Tiempo: {start_time:.1f}s - {end_time:.1f}s"
            )]

    async def _handle_process_youtube_url(self, args: dict) -> list[types.TextContent]:
        """Handle YouTube URL processing - starts background task"""
        youtube_url = args["youtube_url"]
        custom_title = args.get("title", "")

        try:
            # Quick info check first
            info_response = await self._get_youtube_info(youtube_url)
            if info_response.startswith("‚ùå"):
                return [types.TextContent(type="text", text=info_response)]

            # Generate unique task ID
            import time
            task_id = f"youtube_{int(time.time())}"

            # Store initial status
            self.processing_status[task_id] = {
                "status": "starting",
                "step": "Inicializando procesamiento",
                "progress": 0,
                "youtube_url": youtube_url,
                "custom_title": custom_title,
                "start_time": time.time(),
                "error": None,
                "result": None
            }

            # Start background task
            task = asyncio.create_task(self._process_youtube_background(task_id, youtube_url, custom_title))
            self.background_tasks[task_id] = task

            # Return immediate response
            response = "üöÄ **YouTube Processing Iniciado**\n\n"
            response += f"üîó **URL:** {youtube_url}\n"
            response += info_response + "\n"
            response += f"üÜî **Task ID:** `{task_id}`\n\n"
            response += "‚ö° **El procesamiento ha comenzado en segundo plano.**\n\n"
            response += "üìä **Para verificar el progreso:**\n"
            response += f"‚Ä¢ Usa la herramienta `check_youtube_processing` con task_id: `{task_id}`\n"
            response += "‚Ä¢ O simplemente usa `check_youtube_processing` para ver el progreso del √∫ltimo video\n\n"
            response += "‚è±Ô∏è **Esto evita timeouts y permite procesar videos largos.**\n"
            response += "üí° **Te notificaremos cuando est√© listo para b√∫squedas.**"

            return [types.TextContent(type="text", text=response)]

        except Exception as e:
            return [types.TextContent(
                type="text",
                text=f"‚ùå Error iniciando procesamiento de YouTube:\n{e!s}\n\nURL: {youtube_url}"
            )]

    async def _get_youtube_info(self, youtube_url: str) -> str:
        """Get YouTube video info quickly to estimate processing time"""
        try:
            # Quick info check with yt-dlp
            info_process = await asyncio.create_subprocess_exec(
                "yt-dlp",
                "--print", "%(duration)s,%(title)s,%(filesize_approx)s",
                youtube_url,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await info_process.communicate()

            if info_process.returncode != 0:
                return "‚ùå Error obteniendo informaci√≥n del video de YouTube"

            info = stdout.decode().strip().split(',')
            if len(info) >= 2:
                duration = float(info[0]) if info[0] != 'NA' else 0
                title = info[1] if len(info) > 1 else "Video"
                filesize = int(info[2]) if len(info) > 2 and info[2] != 'NA' else 0

                # Estimate processing time (roughly 2x duration for transcription + embeddings)
                estimated_time = max(120, duration * 2)  # minimum 2 minutes

                response = f"üìπ **T√≠tulo:** {title}\n"
                response += f"‚è±Ô∏è **Duraci√≥n:** {duration/60:.1f} minutos\n"
                if filesize > 0:
                    response += f"üì¶ **Tama√±o aprox:** {filesize/(1024*1024):.1f} MB\n"
                response += f"üïê **Tiempo estimado de procesamiento:** {estimated_time/60:.1f} minutos\n"

                if duration > 600:  # 10 minutes
                    response += f"\n‚ö†Ô∏è **ADVERTENCIA:** Este video es largo ({duration/60:.1f} min).\n"
                    response += f"El procesamiento puede tomar **{estimated_time/60:.1f} minutos** y podr√≠a exceder el timeout.\n"
                    response += "üí° **Recomendaci√≥n:** Usa videos m√°s cortos (< 10 min) para evitar timeouts.\n"

                return response
            return "‚ÑπÔ∏è **Video detectado** - procesando informaci√≥n..."

        except Exception as e:
            return f"‚ö†Ô∏è No se pudo obtener informaci√≥n del video: {e!s}"

    async def _process_youtube_background(self, task_id: str, youtube_url: str, custom_title: str):
        """Background YouTube processing task"""
        try:
            project_root = self.dataset_dir.parent if self.dataset_dir else Path("../")

            # Update status: Step 1 - Clean dataset
            self.processing_status[task_id].update({
                "status": "running",
                "step": "üßπ Limpiando dataset anterior",
                "progress": 10
            })

            clean_process = await asyncio.create_subprocess_exec(
                "./clean_dataset.sh",
                "--force",  # Force parameter to skip confirmation
                cwd=str(project_root),
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            clean_stdout, clean_stderr = await clean_process.communicate()

            if clean_process.returncode != 0:
                self.processing_status[task_id].update({
                    "status": "error",
                    "error": f"Error limpiando dataset: {clean_stderr.decode()}"
                })
                return

            # Update status: Step 2 - Download
            self.processing_status[task_id].update({
                "step": "‚¨áÔ∏è Descargando audio de YouTube",
                "progress": 30
            })

            data_dir = project_root / "data"
            data_dir.mkdir(exist_ok=True)

            if custom_title:
                safe_title = "".join(c for c in custom_title if c.isalnum() or c in (' ', '-', '_')).rstrip()
                safe_title = safe_title.replace(' ', '_')
                output_template = f"{safe_title}.%(ext)s"
            else:
                output_template = "%(title)s.%(id)s.%(ext)s"

            ytdlp_command = [
                "yt-dlp", "-x", "--audio-format", "opus", "--audio-quality", "0",
                "-o", str(data_dir / output_template), youtube_url
            ]

            ytdlp_process = await asyncio.create_subprocess_exec(
                *ytdlp_command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            ytdlp_stdout, ytdlp_stderr = await ytdlp_process.communicate()

            if ytdlp_process.returncode != 0:
                self.processing_status[task_id].update({
                    "status": "error",
                    "error": f"Error descargando: {ytdlp_stderr.decode()}"
                })
                return

            # Update status: Step 3 - Process audio
            self.processing_status[task_id].update({
                "step": "üèóÔ∏è Procesando audio (transcripci√≥n y embeddings)",
                "progress": 50
            })

            build_process = await asyncio.create_subprocess_exec(
                "./build_corpus_dataset.sh",
                cwd=str(project_root),
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            build_stdout, build_stderr = await build_process.communicate()

            if build_process.returncode != 0:
                self.processing_status[task_id].update({
                    "status": "error",
                    "error": f"Error procesando: {build_stderr.decode()}"
                })
                return

            # Update status: Step 4 - Reload dataset
            self.processing_status[task_id].update({
                "step": "üîÑ Recargando dataset en MCP server",
                "progress": 90
            })

            if self.client:
                await asyncio.get_event_loop().run_in_executor(
                    None, self.client._load_dataset
                )

                df = self.client.df
                result_summary = {
                    "total_segments": len(df),
                    "unique_files": df['source_file'].nunique(),
                    "total_duration": (df['end_time'] - df['start_time']).sum(),
                    "files": list(df['source_file'].unique()),
                    "sample_texts": df['text'].head(3).tolist()
                }

                self.processing_status[task_id].update({
                    "status": "completed",
                    "step": "‚úÖ Procesamiento completado",
                    "progress": 100,
                    "result": result_summary
                })
            else:
                self.processing_status[task_id].update({
                    "status": "completed_partial",
                    "step": "‚úÖ Audio procesado (reinicia MCP server para cargar)",
                    "progress": 100,
                    "error": "MCP server necesita reinicio manual"
                })

        except Exception as e:
            self.processing_status[task_id].update({
                "status": "error",
                "error": f"Error inesperado: {e!s}"
            })

    async def _handle_check_youtube_processing(self, args: dict) -> list[types.TextContent]:
        """Check YouTube processing status"""
        import time
        task_id = args.get("task_id", "latest")

        # Get latest task if requested
        if task_id == "latest":
            if not self.processing_status:
                return [types.TextContent(
                    type="text",
                    text="‚ùå No hay tareas de YouTube en procesamiento."
                )]
            task_id = max(self.processing_status.keys())

        if task_id not in self.processing_status:
            return [types.TextContent(
                type="text",
                text=f"‚ùå Task ID '{task_id}' no encontrado.\n\nTareas disponibles: {list(self.processing_status.keys())}"
            )]

        status = self.processing_status[task_id]

        response = "üìä **Estado del Procesamiento de YouTube**\n\n"
        response += f"üÜî **Task ID:** {task_id}\n"
        response += f"üîó **URL:** {status['youtube_url']}\n"
        response += f"üìà **Progreso:** {status['progress']}%\n"
        response += f"üîÑ **Estado:** {status['status'].upper()}\n"
        response += f"‚öôÔ∏è **Paso actual:** {status['step']}\n"

        elapsed = time.time() - status['start_time']
        response += f"‚è±Ô∏è **Tiempo transcurrido:** {elapsed/60:.1f} minutos\n\n"

        if status['status'] == 'completed':
            result = status['result']
            response += "üéâ **¬°PROCESAMIENTO COMPLETADO!**\n\n"
            response += "üìä **Resumen del dataset:**\n"
            response += f"  üìà Total de segmentos: {result['total_segments']}\n"
            response += f"  üìÅ Archivos √∫nicos: {result['unique_files']}\n"
            response += f"  ‚è±Ô∏è Duraci√≥n total: {result['total_duration']/60:.1f} minutos\n\n"
            response += "üìÑ **Archivos procesados:**\n"
            for file in result['files']:
                response += f"  ‚Ä¢ {file}\n"
            response += "\nüìù **Muestra del contenido:**\n"
            for i, text in enumerate(result['sample_texts'], 1):
                preview = text[:80] + "..." if len(text) > 80 else text
                response += f"  {i}. {preview}\n"
            response += "\n‚úÖ **El contenido est√° listo para b√∫squedas.**"

        elif status['status'] == 'error':
            response += f"‚ùå **ERROR EN PROCESAMIENTO:**\n{status['error']}\n\n"
            response += "üí° **Posibles soluciones:**\n"
            response += "‚Ä¢ Verifica que la URL de YouTube sea v√°lida\n"
            response += "‚Ä¢ Aseg√∫rate de que yt-dlp est√© instalado\n"
            response += "‚Ä¢ Intenta con un video m√°s corto\n"

        elif status['status'] == 'completed_partial':
            response += f"‚ö†Ô∏è **PROCESAMIENTO PARCIAL:**\n{status.get('error', '')}\n\n"
            response += "üí° **Para completar:** Reinicia el MCP server para cargar el nuevo dataset."

        else:
            progress_bar = "‚ñà" * (status['progress'] // 10) + "‚ñë" * (10 - status['progress'] // 10)
            response += f"‚è≥ **EN PROGRESO** [{progress_bar}]\n\n"
            response += "üí° **Consejo:** Vuelve a verificar en unos minutos."

        return [types.TextContent(type="text", text=response)]

    async def initialize_client(self, dataset_dir: str):
        """Initialize the audio search client"""
        try:
            self.dataset_dir = Path(dataset_dir)
            self.client = AudioDatasetClient(dataset_dir, logger=self.logger)
            await asyncio.get_event_loop().run_in_executor(
                None, self.client._load_dataset
            )
            # Only print status if running in terminal
            if hasattr(sys, 'stdout') and sys.stdout.isatty():
                self.logger.info(f"‚úÖ MCP Server initialized with dataset from: {dataset_dir}")
            return True
        except Exception as e:
            # Always log errors
            self.logger.error(f"‚ùå Failed to initialize MCP server: {e}")
            return False

    def run(self, dataset_dir: str = "../dataset"):
        """Run the MCP server"""
        async def main():
            # Store dataset directory for lazy initialization
            self.dataset_dir = Path(dataset_dir)

            # Run the server immediately without waiting for client initialization
            from mcp.server.stdio import stdio_server
            async with stdio_server() as (read_stream, write_stream):
                # Start client initialization in background
                asyncio.create_task(self._lazy_initialize_client())

                await self.server.run(
                    read_stream,
                    write_stream,
                    InitializationOptions(
                        server_name="audio-search",
                        server_version="1.0.0",
                        capabilities=self.server.get_capabilities(
                            notification_options=NotificationOptions(),
                            experimental_capabilities={}
                        )
                    )
                )

        asyncio.run(main())

    async def _lazy_initialize_client(self):
        """Initialize the client in the background"""
        try:
            if not self.client:
                self.client = AudioDatasetClient(str(self.dataset_dir), logger=self.logger)
                await asyncio.get_event_loop().run_in_executor(
                    None, self.client._load_dataset
                )
                # Only print status if running in terminal
                if hasattr(sys, 'stdout') and sys.stdout.isatty():
                    self.logger.info(f"‚úÖ MCP Server initialized with dataset from: {self.dataset_dir}")
        except Exception as e:
            # Always log errors to stderr
            self.logger.error(f"‚ùå Failed to initialize MCP server: {e}")
            self.client = None

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Audio Search MCP Server")
    parser.add_argument(
        "--dataset-dir",
        default="../dataset",
        help="Path to the dataset directory"
    )

    args = parser.parse_args()

    server = AudioSearchMCPServer()
    server.run(args.dataset_dir)
