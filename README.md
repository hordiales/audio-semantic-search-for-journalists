# BÃºsqueda SemÃ¡ntica en Audios con fines PeriodÃ­sticos

Sistema completo para realizar bÃºsqueda semÃ¡ntica multimodal (texto y audio) de contenido de audio hablado con enfoque en aplicaciones periodÃ­sticas. Permite la bÃºsqueda analizando el texto y el anÃ¡lisis de sentimiento del mismo, pero tambiÃ©n buscar en el audio por eventos de la ontologÃ­a AudioSet (aplausos, gritos, mÃºsica de fondo, etc).

## ğŸ¯ CaracterÃ­sticas

- **Embeddings semÃ¡nticos** de texto con sentence-transformers
- **Embeddings acÃºsticos** con YAMNet segÃºn ontologÃ­a de AudioSet
- **MÃºltiples modelos de audio**: YAMNet, CLAP, SpeechDPR
- **IndexaciÃ³n vectorial** con FAISS, Supabase, ChromaDB
- **TranscripciÃ³n automÃ¡tica** con OpenAI Whisper
- **AnÃ¡lisis de sentimiento** integrado
- **MCP server** para consultar desde LLMs
- **API REST** con FastAPI para funcionar como servicio
- **CLI** para bÃºsqueda interactiva

## ğŸš€ Inicio RÃ¡pido

### Prerequisitos

- **Python 3.11.13** (requerido exactamente) - usar pyenv
- **Poetry** para gestiÃ³n de dependencias (recomendado)
- **ffmpeg** para procesamiento de audio

### InstalaciÃ³n RÃ¡pida

```bash
# 1. Instalar pyenv (si no lo tienes)
# macOS: brew install pyenv
# Linux: curl https://pyenv.run | bash

# 2. Instalar Python 3.11.13
pyenv install 3.11.13
pyenv local 3.11.13

# 3. Instalar Poetry
curl -sSL https://install.python-poetry.org | python3 -

# 4. Clonar e instalar
git clone <url-del-repositorio>
cd audio-semantic-search-for-journalists
poetry install  # âš ï¸ El venv se crea AUTOMÃTICAMENTE aquÃ­
poetry shell    # Opcional: activar venv (o usar 'poetry run' sin activar)

# 5. (Opcional) Instalar extras para YAMNet
poetry install --extras yamnet
```

Para mÃ¡s detalles, ver [doc/INSTALLATION.md](doc/INSTALLATION.md).

**âš ï¸ IMPORTANTE**: Este proyecto requiere exactamente Python 3.11.13. Ver [doc/REQUIREMENTS_PYTHON.md](doc/REQUIREMENTS_PYTHON.md) para mÃ¡s informaciÃ³n.

## ğŸ“– DocumentaciÃ³n

### GuÃ­as Principales

- **[InstalaciÃ³n](doc/INSTALLATION.md)** - GuÃ­a completa de instalaciÃ³n
- **[Inicio RÃ¡pido](doc/QUICK_START.md)** - Empezar en 5 minutos
- **[Arquitectura](doc/ARCHITECTURE_long.md)** - DiseÃ±o del sistema
- **[Dataset](doc/DATASET.md)** - Crear y procesar datasets
- **[Troubleshooting](doc/TROUBLESHOOTING.md)** - SoluciÃ³n de problemas

### Interfaces y APIs

- **[API REST](doc/API_README.md)** - DocumentaciÃ³n de la API FastAPI
- **[MCP Server](doc/MCP_SETUP.md)** - IntegraciÃ³n con LLMs
- **[Aplicaciones](doc/README_APPS.md)** - GuÃ­a de todas las interfaces

### DocumentaciÃ³n TÃ©cnica

- **[Embeddings de Audio](doc/AUDIO_EMBEDDINGS_ARCHITECTURE.md)** - Arquitectura de embeddings
- **[Estrategia de Chunking](doc/ESTRATEGIA_CHUNKING.md)** - SegmentaciÃ³n de audio
- **[EvaluaciÃ³n de Modelos](doc/EMBEDDING_EVALUATION_SYSTEM.md)** - Framework de evaluaciÃ³n

## ğŸ’» Uso

### CLI Interactivo

```bash
poetry run python src/query_client.py ./dataset --interactive
```

### API REST

```bash
# OpciÃ³n 1: API principal (services/app/main.py)
cd services
poetry run python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8080

# Acceder a documentaciÃ³n Swagger
open http://localhost:8080/docs
# O ReDoc: http://localhost:8080/redoc
```

Ver [doc/API_FASTAPI.md](doc/API_FASTAPI.md) para mÃ¡s detalles y opciones.

### Uso ProgramÃ¡tico

```python
from src.semantic_search import SemanticSearchEngine

engine = SemanticSearchEngine()
results = engine.search("economÃ­a y inflaciÃ³n")
```

Ver [doc/QUICK_START.md](doc/QUICK_START.md) para mÃ¡s ejemplos.

## ğŸ“ Estructura del Proyecto

```
audio-semantic-search-for-journalists/
â”œâ”€â”€ src/                    # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ audio_transcription.py
â”‚   â”œâ”€â”€ text_embeddings.py
â”‚   â”œâ”€â”€ audio_embeddings.py
â”‚   â”œâ”€â”€ semantic_search.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ benchmarks/             # Scripts de benchmarks y comparaciÃ³n
â”œâ”€â”€ tools/                  # Herramientas y utilidades
â”‚   â”œâ”€â”€ database/           # Scripts de bases de datos
â”‚   â””â”€â”€ setup/              # Scripts de configuraciÃ³n
â”œâ”€â”€ examples/               # Ejemplos y demos
â”‚   â””â”€â”€ demos/              # Scripts de demostraciÃ³n
â”œâ”€â”€ scripts/                # Scripts de utilidad general
â”‚   â”œâ”€â”€ sql/                # Scripts SQL
â”‚   â””â”€â”€ shell/              # Scripts shell
â”œâ”€â”€ doc/                    # DocumentaciÃ³n
â”œâ”€â”€ tests/                  # Tests
â”œâ”€â”€ mcp_server/            # Servidor MCP
â”œâ”€â”€ services/              # Servicios (GCP, etc.)
â”œâ”€â”€ pyproject.toml         # ConfiguraciÃ³n Poetry
â””â”€â”€ README.md              # Este archivo
```

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno

Crear archivo `.env` en la raÃ­z:

```bash
# APIs opcionales
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...

# ConfiguraciÃ³n de modelos
DEFAULT_WHISPER_MODEL=base
DEFAULT_AUDIO_EMBEDDING_MODEL=yamnet
USE_MOCK_AUDIO=false

# Nivel de logging (DEBUG, INFO, WARNING, ERROR, CRITICAL)
# Por defecto: DEBUG (para desarrollo)
# Para producciÃ³n, cambiar a INFO
LOG_LEVEL=INFO
```

**Nota sobre LOG_LEVEL**:
- El valor por defecto es `DEBUG` para facilitar el desarrollo
- Para producciÃ³n o cuando no necesites logs detallados, configura `LOG_LEVEL=INFO` en tu archivo `.env`
- Esto afecta a todos los scripts del proyecto, incluyendo `scripts/fix_ruff_errors.py`

Ver `src/config_loader.py` para todas las opciones.

## ğŸ§ª Testing

```bash
# Ejecutar todos los tests
poetry run pytest

# Test especÃ­fico
poetry run pytest tests/functional/test_audio_segment_extraction.py
```

## ğŸ“Š Modelos Soportados

### Embeddings de Audio
- **YAMNet**: ClasificaciÃ³n general de audio (1024 dim)
- **CLAP**: BÃºsqueda multimodal audio-texto (512 dim)
- **SpeechDPR**: Dense Passage Retrieval para speech (768 dim)

### Embeddings de Texto
- **Sentence Transformers**: all-MiniLM-L6-v2, all-mpnet-base-v2

### TranscripciÃ³n
- **OpenAI Whisper**: tiny, base, small, medium, large

## ğŸ¤ Contribuir

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia GPLv3. Ver `LICENSE` para mÃ¡s detalles.

## ğŸ”— Referencias

- [OpenAI Whisper](https://github.com/openai/whisper)
- [Sentence Transformers](https://github.com/UKPLab/sentence-transformers)
- [FAISS](https://github.com/facebookresearch/faiss)
- [YAMNet](https://github.com/tensorflow/models/tree/master/research/audioset/yamnet)
- [FastAPI](https://fastapi.tiangolo.com/)

## ğŸ“ Soporte

- **DocumentaciÃ³n**: Ver `doc/` para guÃ­as detalladas
- **Problemas**: Ver [doc/TROUBLESHOOTING.md](doc/TROUBLESHOOTING.md)
- **Issues**: Abrir un issue en el repositorio

---

**VersiÃ³n**: 1.0.0
**Python**: 3.11.13 (requerido exactamente)
**Ãšltima actualizaciÃ³n**: Enero 2025
