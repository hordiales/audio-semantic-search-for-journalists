# B√∫squeda Sem√°ntica en Audios con fines Period√≠sticos

Sistema completo para realizar b√∫squeda sem√°ntica multimodal (texto y audio) de contenido de audio hablado con enfoque en aplicaciones period√≠sticas. Permite la b√∫squeda analizando el texto y el an√°lisis de sentimiento del mismo, pero tambi√©n buscar en el audio por eventos de la ontolog√≠a AudioSet (aplausos, gritos, m√∫sica de fondo, etc).

## üéØ Caracter√≠sticas

- **Embeddings sem√°nticos** de texto con sentence-transformers
- **Embeddings ac√∫sticos** con YAMNet seg√∫n ontolog√≠a de AudioSet
- **M√∫ltiples modelos de audio**: YAMNet, CLAP, SpeechDPR
- **Indexaci√≥n vectorial** con FAISS, Supabase, ChromaDB
- **Transcripci√≥n autom√°tica** con OpenAI Whisper
- **An√°lisis de sentimiento** integrado
- **MCP server** para consultar desde LLMs
- **API REST** con FastAPI para funcionar como servicio
- **CLI** para b√∫squeda interactiva

## üöÄ Inicio R√°pido

### Prerequisitos

- **Python 3.11.13** (requerido exactamente) - usar pyenv
- **Poetry** para gesti√≥n de dependencias (recomendado)
- **ffmpeg** para procesamiento de audio

### Instalaci√≥n R√°pida

```bash
# 1. Instalar pyenv (si no lo tienes)
# macOS: brew install pyenv
# Linux: curl https://pyenv.run | bash

# 2. Instalar Python 3.11.13
pyenv install 3.11.13
pyenv local 3.11.13

# 3. Instalar Poetry
curl -sSL https://install.python-poetry.org | python3 -

# 4. Clonar e instalar
git clone <url-del-repositorio>
cd audio-semantic-search-for-journalists
poetry install  # ‚ö†Ô∏è El venv se crea AUTOM√ÅTICAMENTE aqu√≠
poetry shell    # Opcional: activar venv (o usar 'poetry run' sin activar)

# 5. (Opcional) Instalar extras para YAMNet
poetry install --extras yamnet
```

Para m√°s detalles, ver [docs/INSTALL.md](docs/INSTALL.md).

**‚ö†Ô∏è IMPORTANTE**: Este proyecto requiere exactamente Python 3.11.13.

## üìñ Documentaci√≥n

### Gu√≠as Principales

- **[Instalaci√≥n](docs/INSTALL.md)** - Gu√≠a completa de instalaci√≥n
- **[Gu√≠a Completa: Dataset y B√∫squeda](docs/GUIA_DATASET_Y_BUSQUEDA.md)** - üÜï Paso a paso para generar dataset y usar CLI
- **[Dataset](docs/DATASET.md)** - Crear y procesar datasets
- **[README Principal de Docs](docs/README.md)** - √çndice completo de documentaci√≥n

### Interfaces y APIs

- **[API REST](doc/API_README.md)** - Documentaci√≥n de la API FastAPI
- **[MCP Server](doc/MCP_SETUP.md)** - Integraci√≥n con LLMs
- **[Aplicaciones](doc/README_APPS.md)** - Gu√≠a de todas las interfaces

### Documentaci√≥n T√©cnica

- **[Embeddings de Audio](doc/AUDIO_EMBEDDINGS_ARCHITECTURE.md)** - Arquitectura de embeddings
- **[Estrategia de Chunking](doc/ESTRATEGIA_CHUNKING.md)** - Segmentaci√≥n de audio
- **[Evaluaci√≥n de Modelos](doc/EMBEDDING_EVALUATION_SYSTEM.md)** - Framework de evaluaci√≥n

## üíª Uso

### CLI Interactivo

**CLI de b√∫squeda local con FAISS (Recomendado):**
```bash
# Solo requiere dataset local - no necesita Supabase ni internet
poetry run python examples/demos/cli_audio_search.py ./dataset
```

**CLI alternativo:**
```bash
poetry run python src/query_client.py ./dataset --interactive
```

Ver [docs/GUIA_DATASET_Y_BUSQUEDA.md](docs/GUIA_DATASET_Y_BUSQUEDA.md) para gu√≠a completa paso a paso.

### API REST

```bash
# Opci√≥n 1: API principal (services/app/main.py)
cd services
poetry run python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8080

# Acceder a documentaci√≥n Swagger
open http://localhost:8080/docs
# O ReDoc: http://localhost:8080/redoc
```

Ver [doc/API_FASTAPI.md](doc/API_FASTAPI.md) para m√°s detalles y opciones.

### Uso Program√°tico

```python
from src.semantic_search import SemanticSearchEngine

engine = SemanticSearchEngine()
results = engine.search("econom√≠a y inflaci√≥n")
```

Ver [doc/QUICK_START.md](doc/QUICK_START.md) para m√°s ejemplos.

## üìÅ Estructura del Proyecto

```
audio-semantic-search-for-journalists/
‚îú‚îÄ‚îÄ src/                    # C√≥digo fuente principal
‚îÇ   ‚îú‚îÄ‚îÄ audio_transcription.py
‚îÇ   ‚îú‚îÄ‚îÄ text_embeddings.py
‚îÇ   ‚îú‚îÄ‚îÄ audio_embeddings.py
‚îÇ   ‚îú‚îÄ‚îÄ semantic_search.py
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ benchmarks/             # Scripts de benchmarks y comparaci√≥n
‚îú‚îÄ‚îÄ tools/                  # Herramientas y utilidades
‚îÇ   ‚îú‚îÄ‚îÄ database/           # Scripts de bases de datos
‚îÇ   ‚îî‚îÄ‚îÄ setup/              # Scripts de configuraci√≥n
‚îú‚îÄ‚îÄ examples/               # Ejemplos y demos
‚îÇ   ‚îî‚îÄ‚îÄ demos/              # Scripts de demostraci√≥n
‚îú‚îÄ‚îÄ scripts/                # Scripts de utilidad general
‚îÇ   ‚îú‚îÄ‚îÄ sql/                # Scripts SQL
‚îÇ   ‚îî‚îÄ‚îÄ shell/              # Scripts shell
‚îú‚îÄ‚îÄ doc/                    # Documentaci√≥n
‚îú‚îÄ‚îÄ tests/                  # Tests
‚îú‚îÄ‚îÄ mcp_server/            # Servidor MCP
‚îú‚îÄ‚îÄ services/              # Servicios (GCP, etc.)
‚îú‚îÄ‚îÄ pyproject.toml         # Configuraci√≥n Poetry
‚îî‚îÄ‚îÄ README.md              # Este archivo
```

## üîß Configuraci√≥n

### Variables de Entorno

Crear archivo `.env` en la ra√≠z:

```bash
# APIs opcionales
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...

# Configuraci√≥n de modelos
DEFAULT_WHISPER_MODEL=base
DEFAULT_AUDIO_EMBEDDING_MODEL=yamnet
USE_MOCK_AUDIO=false

# Nivel de logging (DEBUG, INFO, WARNING, ERROR, CRITICAL)
# Por defecto: DEBUG (para desarrollo)
# Para producci√≥n, cambiar a INFO
LOG_LEVEL=INFO
```

**Nota sobre LOG_LEVEL**:
- El valor por defecto es `DEBUG` para facilitar el desarrollo
- Para producci√≥n o cuando no necesites logs detallados, configura `LOG_LEVEL=INFO` en tu archivo `.env`
- Esto afecta a todos los scripts del proyecto, incluyendo `scripts/fix_ruff_errors.py`

Ver `src/config_loader.py` para todas las opciones.

## üß™ Testing

```bash
# Ejecutar todos los tests
poetry run pytest

# Test espec√≠fico
poetry run pytest tests/functional/test_audio_segment_extraction.py
```

## üîç Pre-commit Hooks (Ruff)

El proyecto incluye pre-commit hooks que ejecutan ruff autom√°ticamente antes de cada commit para mantener la calidad del c√≥digo:

```bash
# 1. Instalar pre-commit (incluido en poetry install)
poetry install

# 2. Instalar los hooks de git
poetry run pre-commit install

# 3. (Opcional) Ejecutar manualmente en todos los archivos
poetry run pre-commit run --all-files
```

**Qu√© hace autom√°ticamente:**
- ‚úÖ Ejecuta ruff linting y corrige errores autom√°ticamente
- ‚úÖ Formatea el c√≥digo con ruff
- ‚úÖ Verifica archivos YAML, JSON, TOML
- ‚úÖ Verifica que no se suban archivos grandes
- ‚úÖ Elimina espacios en blanco al final de l√≠neas

**Si un hook falla:**
- Ruff intenta corregir autom√°ticamente los errores
- Si hay errores que no se pueden corregir autom√°ticamente, el commit se bloquea
- Revisa los errores, corr√≠gelos y vuelve a intentar el commit

Ver [docs/comandos-√∫tiles.md](docs/comandos-√∫tiles.md) para m√°s detalles.

## üìä Modelos Soportados

### Embeddings de Audio
- **YAMNet**: Clasificaci√≥n general de audio (1024 dim)
- **CLAP**: B√∫squeda multimodal audio-texto (512 dim)
- **SpeechDPR**: Dense Passage Retrieval para speech (768 dim)

### Embeddings de Texto
- **Sentence Transformers**: all-MiniLM-L6-v2, all-mpnet-base-v2

### Transcripci√≥n
- **OpenAI Whisper**: tiny, base, small, medium, large

## ü§ù Contribuir

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la licencia GPLv3. Ver `LICENSE` para m√°s detalles.

## üîó Referencias

- [OpenAI Whisper](https://github.com/openai/whisper)
- [Sentence Transformers](https://github.com/UKPLab/sentence-transformers)
- [FAISS](https://github.com/facebookresearch/faiss)
- [YAMNet](https://github.com/tensorflow/models/tree/master/research/audioset/yamnet)
- [FastAPI](https://fastapi.tiangolo.com/)

## üîß Troubleshooting

### Error: `NotImplementedError: Could not run 'aten::empty.memory_format' with arguments from the 'SparseMPS' backend`

**Problema**: Whisper falla al cargarse en MPS (Apple Silicon) debido a limitaciones del backend con operaciones de tensores dispersos.

**Soluci√≥n autom√°tica**: El c√≥digo detecta este error y autom√°ticamente hace fallback a CPU. Ver√°s un mensaje de advertencia:

```
‚ö†Ô∏è  Error cargando modelo en MPS: ...
   Cambiando a CPU (MPS tiene limitaciones con algunas operaciones de Whisper)
```

**Forzar CPU desde el inicio** (opcional):
```bash
export WHISPER_DEVICE=cpu
poetry run python src/simple_dataset_pipeline.py --input data/ --output ./dataset
```

Para m√°s detalles sobre GPU y MPS, ver [docs/GPU_CONSIDERATIONS.md](docs/GPU_CONSIDERATIONS.md).

### Error: `No module named 'triton'` en macOS

**Esperado.** Triton no est√° disponible para macOS. El c√≥digo funciona sin √©l. Si `poetry install` falla por triton:

```bash
# Crear venv (puede fallar en triton, pero crea el venv)
poetry install || true

# Instalar dependencias con pip (ignora triton)
poetry run pip install -r requirements.txt
```

### Error: TensorFlow no disponible (YAMNet)

Si ves el mensaje `‚ö†Ô∏è TensorFlow no disponible. YAMNet no estar√° disponible.`:

```bash
# Instalar extras para YAMNet
poetry install --extras yamnet
```

### Problemas con Python 3.11.13

Este proyecto requiere exactamente Python 3.11.13. Si tienes otra versi√≥n:

```bash
# Con pyenv
pyenv install 3.11.13
pyenv local 3.11.13

# Verificar versi√≥n
python --version  # Debe mostrar 3.11.13
```

Para m√°s problemas, ver [docs/GPU_CONSIDERATIONS.md](docs/GPU_CONSIDERATIONS.md) y [docs/INSTALL.md](docs/INSTALL.md).

## üìû Soporte

- **Documentaci√≥n**: Ver `docs/` para gu√≠as detalladas
- **Problemas de GPU/MPS**: Ver [docs/GPU_CONSIDERATIONS.md](docs/GPU_CONSIDERATIONS.md)
- **Problemas de instalaci√≥n**: Ver [docs/INSTALL.md](docs/INSTALL.md)
- **Issues**: Abrir un issue en el repositorio

---

**Versi√≥n**: 1.0.0
**Python**: 3.11.13 (requerido exactamente)
**√öltima actualizaci√≥n**: Enero 2025
