# B√∫squeda Sem√°ntica en Audios con fines Period√≠sticos

Conjunto de aplicaciones para realizar b√∫squeda sem√°ntica multimodal (texto y audio) de contenido de audio hablado con enfoque en aplicaciones period√≠sticas. Permite la b√∫squeda analizando el texto y el an√°lisis de sentimiento del mismo, pero tambi√©n asi buscar en el audio por eventos de la ontolog√≠a AudioSet (aplausos, gritos, m√∫sica de fondo, etc)

## Caracter√≠sticas

- **Embeddings sem√°nticos** de texto con sentence-transformers
- **Embeddings ac√∫sticos** con YAMNet seg√∫n ontolog√≠a de AudioSet
- **Indexaci√≥n vectorial** con FAISS
- **Transcripci√≥n autom√°tica** con OpenAI Whisper
- **MCP server** para consultar desde LLMs
- [IN-PROGRESS] **Construcci√≥n del dataset orquestada** con Dagster
- **API Rest** con FastAPI para funcionar como servicio para otras aplicaciones

## Instalaci√≥n

### Prerequisitos

- **Python 3.11.13** (usando pyenv)
- **Poetry** para gesti√≥n de dependencias
- **ffmpeg** para procesamiento de audio

### Instalaci√≥n con Poetry (Recomendado)

```bash
# 1. Instalar pyenv (si no lo tienes)
# macOS: brew install pyenv
# Linux: https://github.com/pyenv/pyenv#installation

# 2. Instalar Python 3.11.13 con pyenv
pyenv install 3.11.13
pyenv local 3.11.13

# 3. Instalar Poetry (si no lo tienes)
curl -sSL https://install.python-poetry.org | python3 -

# 4. Clonar el repositorio
git clone <url-del-repositorio>
cd audio-semantic-search-for-journalists

# 5. Instalar dependencias con Poetry
poetry install

# 6. Activar el entorno virtual
poetry shell

# 7. (Opcional) Instalar extras para YAMNet
poetry install --extras yamnet
```

### Instalaci√≥n Alternativa (pip)

Si prefieres usar pip en lugar de Poetry:

```bash
# 1. Configurar Python con pyenv
pyenv install 3.11.13
pyenv local 3.11.13

# 2. Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. (Opcional) Instalar TensorFlow para YAMNet
pip install tensorflow tensorflow-hub
```

### Instalaci√≥n de ffmpeg

**macOS:**
```bash
brew install ffmpeg
```

**Ubuntu/Debian:**
```bash
sudo apt-get update
sudo apt-get install ffmpeg
```

**Windows:**
Descargar desde [ffmpeg.org](https://ffmpeg.org/download.html) y a√±adir al PATH.

IMPORTANTE: probado con python=3.11.13  
M√°s detalles y troubleshooting en [[INSTALL.md]]



## üìÅ Estructura del proyecto

```
semantic-search-periodismo/
‚îú‚îÄ‚îÄ requirements.txt           # Dependencias del proyecto
‚îú‚îÄ‚îÄ audio_transcription.py     # M√≥dulo de transcripci√≥n con Whisper
‚îú‚îÄ‚îÄ text_embeddings.py         # Generaci√≥n de embeddings de texto
‚îú‚îÄ‚îÄ audio_embeddings.py        # Generaci√≥n de embeddings de audio
‚îú‚îÄ‚îÄ vector_indexing.py         # Indexaci√≥n vectorial con FAISS
‚îú‚îÄ‚îÄ semantic_search.py         # Motor de b√∫squeda principal
‚îú‚îÄ‚îÄ example_usage.py           # Ejemplos de uso
‚îî‚îÄ‚îÄ README.md                  # Este archivo
```

TODO: add diagrama de arquitectura

# Audioset ontology



## Uso

De ser necesario ajustar eventos en detect_audio_events.py
```python
        thresholds = {
            'laughter': 0.2,    # Reducido: risas en radio suelen ser m√°s suaves
            'applause': 0.20,    # Muy reducido: era el m√°s alto (0.4), ahora igual que m√∫sica
            'music': 0.2,        # Mantener: funciona bien
            'singing': 0.25,     # Mantener: funciona bien
            'crowd': 0.18,       # Reducido: ruido de multitud suele ser de fondo
            'speech': 0.4,       # Mantener: debe ser bien detectado
            'cheering': 0.3,    # Reducido: v√≠tores suelen mezclarse con otros sonidos
            'booing': 0.25       # Ligero ajuste: abucheos suelen ser m√°s claros
        }
```
### Crear dataset/corpus

    Ubicar archivos de audio (mp3, ogg, wav, etc) en ./data

    Ejecutar pipeline:
        - Conversi√≥n a wav
        - SpeechToText tool
        - C√°lculo de embeddings texto
        - C√°lculo de embeddings audio
        - An√°lisis de sentimiento

Detalle de como construirlo en [[DATASET.md]]

Dataset de referencia [Europarl-ST](https://www.mllp.upv.es/europarl-st/) is a multilingual Spoken Language Translation corpus containing paired audio-text samples for SLT from and into 9 European languages, for a total of 72 different translation directions. This corpus has been compiled using the debates held in the European Parliament in the period between 2008 and 2012.
Nota: Este dataset ya contiene las transcripciones (evita el paso de speech2text)



    En ./dataset quedar√° la siguiente estructura

# Consulta (query) por l√≠nea de comando

    $ python src/query_client.py ./dataset --interactive

"""
Sistema h√≠brido de b√∫squeda de audio que combina:
1. B√∫squeda por palabras clave (siempre funciona)
2. B√∫squeda con embeddings YAMNet reales (si est√°n disponibles)
"""


# Configuraci√≥n

## Config entorno
Revisar m√≥dulo config_loader.py
y archivo .env para variables de entorno

dataset/search_config.json 


## Config de consulta

"""
Configuraci√≥n de par√°metros de b√∫squeda y filtros de score
"""

### Umbrales de score
    min_text_score: float = 0.3
    min_audio_score: float = 0.3
    min_hybrid_score: float = 0.3
    min_keyword_score: float = 0.3
    min_yamnet_score: float = 0.5


### Consulta

Modo interactivo por l√≠nea de comando: 
    $ python query_client.py ./dataset --interactive --load-real

# Referencias

- [OpenAI Whisper](https://github.com/openai/whisper)
- [Sentence Transformers](https://github.com/UKPLab/sentence-transformers)
- [FAISS](https://github.com/facebookresearch/faiss)
- [YAMNet](https://github.com/tensorflow/models/tree/master/research/audioset/yamnet)
    Audioset
- [FastAPI](https://fastapi.tiangolo.com/)

## Licencia

Este proyecto est√° bajo la licencia GPLv3. Ver `LICENSE` para m√°s detalles.
