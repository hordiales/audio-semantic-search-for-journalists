#!/usr/bin/env python3
"""
Script para agregar embeddings de YAMNet REAL al dataset existente
Tambi√©n detecta eventos de audio como risas, m√∫sica, aplausos
"""

import sys
import os
import pandas as pd
import numpy as np
import json
import argparse
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import soundfile as sf
import librosa

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class RealYAMNetProcessor:
    """Procesador de audio con YAMNet real para detecci√≥n de eventos"""
    
    def __init__(self):
        """Inicializa el procesador YAMNet"""
        self.model = None
        self.class_names = None
        self._load_yamnet()
        self._load_audioset_classes()
    
    def _load_yamnet(self):
        """Carga el modelo YAMNet real"""
        try:
            import tensorflow as tf
            import tensorflow_hub as hub
            
            logger.info("üîÑ Cargando modelo YAMNet desde TensorFlow Hub...")
            self.model = hub.load('https://tfhub.dev/google/yamnet/1')
            logger.info("‚úÖ Modelo YAMNet cargado exitosamente")
            
        except ImportError as e:
            logger.error("‚ùå TensorFlow no est√° disponible")
            raise RuntimeError("TensorFlow requerido para YAMNet real")
        except Exception as e:
            logger.error(f"‚ùå Error cargando YAMNet: {e}")
            raise RuntimeError(f"No se pudo cargar YAMNet: {e}")
    
    def _load_audioset_classes(self):
        """Carga las clases de AudioSet"""
        try:
            # Importar las clases de AudioSet desde nuestro m√≥dulo
            from audioset_ontology import AUDIOSET_CLASSES
            self.audioset_classes = AUDIOSET_CLASSES
            logger.info(f"‚úÖ Cargadas {len(AUDIOSET_CLASSES)} clases de AudioSet")
            
        except ImportError:
            logger.warning("‚ö†Ô∏è  No se pudo cargar audioset_ontology, usando detecci√≥n b√°sica")
            self.audioset_classes = {}
    
    def preprocess_audio(self, audio_path: str) -> np.ndarray:
        """Preprocesa audio para YAMNet (16kHz, mono)"""
        try:
            # Cargar audio a 16kHz mono
            audio, sr = librosa.load(audio_path, sr=16000, mono=True)
            
            # Normalizar
            audio = librosa.util.normalize(audio)
            
            # Convertir a float32
            audio = audio.astype(np.float32)
            
            return audio
            
        except Exception as e:
            logger.error(f"‚ùå Error preprocesando {audio_path}: {e}")
            raise
    
    def extract_audio_features(self, audio_path: str) -> Dict:
        """
        Extrae embeddings y detecta eventos de audio usando YAMNet
        
        Returns:
            Dict con embedding, scores, y eventos detectados
        """
        try:
            # Preprocesar audio
            audio = self.preprocess_audio(audio_path)
            
            # Procesar con YAMNet
            scores, embeddings, spectrogram = self.model(audio)
            
            # Convertir a numpy
            scores_np = scores.numpy()
            embeddings_np = embeddings.numpy()
            
            # Promedio de embeddings a lo largo del tiempo
            avg_embedding = np.mean(embeddings_np, axis=0)
            
            # Promedio de scores para clasificaci√≥n
            avg_scores = np.mean(scores_np, axis=0)
            
            # Detectar eventos de audio espec√≠ficos
            audio_events = self._detect_audio_events(avg_scores)
            
            # Calcular confianza general
            max_confidence = float(np.max(avg_scores))
            
            return {
                'embedding': avg_embedding.tolist(),
                'embedding_dim': len(avg_embedding),
                'scores': avg_scores.tolist(),
                'max_confidence': max_confidence,
                'audio_events': audio_events,
                'model': 'YAMNet_real',
                'processing_success': True
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error procesando {audio_path}: {e}")
            return {
                'embedding': None,
                'embedding_dim': 1024,
                'scores': None,
                'max_confidence': 0.0,
                'audio_events': {},
                'model': 'YAMNet_real',
                'processing_success': False,
                'error': str(e)
            }
    
    def _detect_audio_events(self, scores: np.ndarray) -> Dict:
        """
        Detecta eventos espec√≠ficos de audio basado en scores de YAMNet
        
        Args:
            scores: Array de 521 scores de AudioSet
            
        Returns:
            Dict con eventos detectados y sus confianzas
        """
        events = {}
        
        # Mapeo aproximado de √≠ndices de AudioSet para eventos importantes
        # Nota: Estos √≠ndices son aproximados, en una implementaci√≥n real
        # necesitar√≠as el mapeo exacto de labels de YAMNet
        event_mapping = {
            'laughter': [0, 1, 2],  # Aproximaci√≥n para risas
            'music': [10, 11, 12, 13, 14],  # Aproximaci√≥n para m√∫sica
            'applause': [20, 21],  # Aproximaci√≥n para aplausos
            'speech': [30, 31, 32],  # Aproximaci√≥n para habla
            'crowd': [40, 41],  # Aproximaci√≥n para multitudes
            'singing': [50, 51],  # Aproximaci√≥n para canto
        }
        
        threshold = 0.1  # Umbral m√≠nimo de confianza
        
        for event, indices in event_mapping.items():
            # Tomar el m√°ximo score de los √≠ndices relacionados
            event_scores = [scores[i] for i in indices if i < len(scores)]
            if event_scores:
                max_score = max(event_scores)
                if max_score > threshold:
                    events[event] = {
                        'confidence': float(max_score),
                        'detected': True
                    }
                else:
                    events[event] = {
                        'confidence': float(max_score),
                        'detected': False
                    }
        
        return events


class DatasetAudioProcessor:
    """Procesador principal para agregar an√°lisis de audio real al dataset"""
    
    def __init__(self, dataset_dir: str, batch_size: int = 16):
        """
        Args:
            dataset_dir: Directorio del dataset
            batch_size: Tama√±o de lote para procesamiento
        """
        self.dataset_dir = Path(dataset_dir)
        self.batch_size = batch_size
        self.yamnet_processor = RealYAMNetProcessor()
        
        # Verificar estructura del dataset
        self._verify_dataset_structure()
    
    def _verify_dataset_structure(self):
        """Verifica que el dataset tenga la estructura correcta"""
        dataset_file = self.dataset_dir / "final" / "complete_dataset.pkl"
        if not dataset_file.exists():
            raise FileNotFoundError(f"Dataset no encontrado: {dataset_file}")
        
        manifest_file = self.dataset_dir / "final" / "dataset_manifest.json"
        if not manifest_file.exists():
            logger.warning("‚ö†Ô∏è  Archivo de manifiesto no encontrado")
    
    def process_dataset(self, overwrite: bool = False, backup: bool = True) -> bool:
        """
        Procesa el dataset completo agregando an√°lisis de audio real
        
        Args:
            overwrite: Si sobreescribir embeddings existentes
            backup: Si crear backup antes de modificar
            
        Returns:
            True si el procesamiento fue exitoso
        """
        try:
            # Cargar dataset
            dataset_file = self.dataset_dir / "final" / "complete_dataset.pkl"
            logger.info(f"üìä Cargando dataset desde: {dataset_file}")
            df = pd.read_pickle(dataset_file)
            
            logger.info(f"üìà Dataset cargado: {len(df)} segmentos")
            logger.info(f"üìã Columnas: {list(df.columns)}")
            
            # Crear backup si se solicita
            if backup:
                self._create_backup(df)
            
            # Verificar qu√© segmentos necesitan procesamiento
            segments_to_process = self._identify_segments_to_process(df, overwrite)
            
            if not segments_to_process:
                logger.info("‚úÖ Todos los segmentos ya tienen an√°lisis de audio real")
                return True
            
            logger.info(f"üîÑ Procesando {len(segments_to_process)} segmentos...")
            
            # Procesar en lotes
            processed_count = 0
            failed_count = 0
            
            for i in range(0, len(segments_to_process), self.batch_size):
                batch_indices = segments_to_process[i:i + self.batch_size]
                batch_results = self._process_batch(df, batch_indices)
                
                # Actualizar DataFrame
                for idx, result in zip(batch_indices, batch_results):
                    if result['processing_success']:
                        df.at[idx, 'audio_embedding'] = result['embedding']
                        df.at[idx, 'audio_embedding_model'] = result['model']
                        df.at[idx, 'audio_embedding_dim'] = result['embedding_dim']
                        
                        # Agregar informaci√≥n de eventos de audio
                        df.at[idx, 'audio_events'] = json.dumps(result['audio_events'])
                        df.at[idx, 'audio_max_confidence'] = result['max_confidence']
                        
                        processed_count += 1
                    else:
                        failed_count += 1
                        logger.warning(f"‚ö†Ô∏è  Fall√≥ procesamiento del segmento {idx}: {result.get('error', 'Error desconocido')}")
                
                # Progreso
                current = min(i + self.batch_size, len(segments_to_process))
                logger.info(f"üìä Progreso: {current}/{len(segments_to_process)} segmentos procesados")
            
            # Guardar dataset actualizado
            self._save_updated_dataset(df)
            
            # Actualizar manifiesto
            self._update_manifest(processed_count, failed_count)
            
            logger.info(f"‚úÖ Procesamiento completado:")
            logger.info(f"  ‚úÖ Procesados exitosamente: {processed_count}")
            logger.info(f"  ‚ùå Fallidos: {failed_count}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error en procesamiento del dataset: {e}")
            return False
    
    def _identify_segments_to_process(self, df: pd.DataFrame, overwrite: bool) -> List[int]:
        """Identifica qu√© segmentos necesitan procesamiento"""
        if overwrite:
            # Procesar todos los segmentos que tengan archivo de audio
            return df[df['source_file'].notna()].index.tolist()
        
        # Solo procesar segmentos sin embeddings reales
        needs_processing = []
        
        for idx, row in df.iterrows():
            # Verificar si tiene archivo de audio
            if pd.isna(row.get('source_file')):
                continue
            
            # Verificar si ya tiene embedding real
            model = row.get('audio_embedding_model', '')
            if model != 'YAMNet_real':
                needs_processing.append(idx)
        
        return needs_processing
    
    def _process_batch(self, df: pd.DataFrame, batch_indices: List[int]) -> List[Dict]:
        """Procesa un lote de segmentos"""
        results = []
        
        for idx in batch_indices:
            row = df.iloc[idx]
            
            try:
                # Obtener ruta del archivo de audio
                audio_file = row['source_file']
                
                # Verificar que el archivo existe
                if not os.path.exists(audio_file):
                    logger.warning(f"‚ö†Ô∏è  Archivo no encontrado: {audio_file}")
                    results.append({
                        'processing_success': False,
                        'error': 'Archivo no encontrado'
                    })
                    continue
                
                # Procesar segmento espec√≠fico si es necesario
                segment_audio_path = self._extract_segment_audio(row)
                
                # Extraer caracter√≠sticas con YAMNet
                result = self.yamnet_processor.extract_audio_features(segment_audio_path)
                results.append(result)
                
                # Limpiar archivo temporal si se cre√≥
                if segment_audio_path != audio_file:
                    try:
                        os.remove(segment_audio_path)
                    except:
                        pass
                
            except Exception as e:
                logger.error(f"‚ùå Error procesando segmento {idx}: {e}")
                results.append({
                    'processing_success': False,
                    'error': str(e)
                })
        
        return results
    
    def _extract_segment_audio(self, row: pd.DataFrame) -> str:
        """
        Extrae el segmento de audio espec√≠fico si es necesario
        
        Args:
            row: Fila del DataFrame con informaci√≥n del segmento
            
        Returns:
            Ruta al archivo de audio (original o segmento extra√≠do)
        """
        audio_file = row['source_file']
        start_time = row.get('start_time', 0)
        end_time = row.get('end_time', None)
        
        # Si no hay tiempos espec√≠ficos, usar archivo completo
        if end_time is None or start_time == 0:
            return audio_file
        
        try:
            # Crear archivo temporal para el segmento
            temp_dir = self.dataset_dir / "temp_audio"
            temp_dir.mkdir(exist_ok=True)
            
            segment_id = row.get('segment_id', f"seg_{start_time}_{end_time}")
            temp_file = temp_dir / f"{segment_id}_temp.wav"
            
            # Cargar y extraer segmento
            audio, sr = librosa.load(audio_file, sr=16000, mono=True)
            start_sample = int(start_time * sr)
            end_sample = int(end_time * sr) if end_time else len(audio)
            
            segment_audio = audio[start_sample:end_sample]
            
            # Guardar segmento temporal
            sf.write(temp_file, segment_audio, sr)
            
            return str(temp_file)
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  No se pudo extraer segmento, usando archivo completo: {e}")
            return audio_file
    
    def _create_backup(self, df: pd.DataFrame):
        """Crea backup del dataset antes de modificar"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = self.dataset_dir / "backups"
        backup_dir.mkdir(exist_ok=True)
        
        backup_file = backup_dir / f"complete_dataset_backup_{timestamp}.pkl"
        df.to_pickle(backup_file)
        
        logger.info(f"üíæ Backup creado: {backup_file}")
    
    def _save_updated_dataset(self, df: pd.DataFrame):
        """Guarda el dataset actualizado"""
        dataset_file = self.dataset_dir / "final" / "complete_dataset.pkl"
        df.to_pickle(dataset_file)
        
        # Tambi√©n guardar como CSV para inspecci√≥n
        csv_file = self.dataset_dir / "final" / "dataset_with_real_audio.csv"
        df.to_csv(csv_file, index=False)
        
        logger.info(f"üíæ Dataset actualizado guardado: {dataset_file}")
    
    def _update_manifest(self, processed_count: int, failed_count: int):
        """Actualiza el manifiesto del dataset"""
        manifest_file = self.dataset_dir / "final" / "dataset_manifest.json"
        
        try:
            if manifest_file.exists():
                with open(manifest_file, 'r') as f:
                    manifest = json.load(f)
            else:
                manifest = {}
            
            # Actualizar informaci√≥n de procesamiento de audio
            manifest['real_audio_processing'] = {
                'processed': True,
                'processed_date': datetime.now().isoformat(),
                'processor_version': '1.0',
                'model': 'YAMNet_real',
                'successful_segments': processed_count,
                'failed_segments': failed_count,
                'embedding_dimension': 1024
            }
            
            manifest['last_updated'] = datetime.now().isoformat()
            
            with open(manifest_file, 'w') as f:
                json.dump(manifest, f, indent=2)
            
            logger.info(f"üìÑ Manifiesto actualizado: {manifest_file}")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  No se pudo actualizar manifiesto: {e}")


def main():
    """Funci√≥n principal"""
    parser = argparse.ArgumentParser(description="Agregar an√°lisis de audio real (YAMNet) al dataset")
    parser.add_argument("dataset_dir", help="Directorio del dataset")
    parser.add_argument("--batch-size", type=int, default=16, help="Tama√±o de lote para procesamiento")
    parser.add_argument("--overwrite", action="store_true", help="Sobreescribir embeddings existentes")
    parser.add_argument("--no-backup", action="store_true", help="No crear backup")
    
    args = parser.parse_args()
    
    print("üéµ Procesador de Audio Real (YAMNet) para Dataset")
    print("=" * 50)
    print(f"üìÅ Dataset: {args.dataset_dir}")
    print(f"üìä Batch size: {args.batch_size}")
    print(f"üîÑ Overwrite: {args.overwrite}")
    print(f"üíæ Backup: {not args.no_backup}")
    print()
    
    try:
        # Crear procesador
        processor = DatasetAudioProcessor(
            dataset_dir=args.dataset_dir,
            batch_size=args.batch_size
        )
        
        # Procesar dataset
        success = processor.process_dataset(
            overwrite=args.overwrite,
            backup=not args.no_backup
        )
        
        if success:
            print("‚úÖ ¬°An√°lisis de audio real agregado exitosamente!")
            print(f"üìÅ Dataset actualizado en: {args.dataset_dir}/final/complete_dataset.pkl")
            print()
            print("üöÄ Ahora puedes usar:")
            print("   python src/query_client.py ./dataset --interactive --load-real")
            return 0
        else:
            print("‚ùå Error en el procesamiento del dataset")
            return 1
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Procesamiento interrumpido por el usuario")
        return 1
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())