#!/usr/bin/env python3
"""
Script para ejecutar el pipeline de generaci√≥n de dataset
"""

import argparse
import json
import sys
from pathlib import Path
from datetime import datetime

from dataset_orchestrator import DatasetOrchestrator, DatasetConfig
from config_loader import get_config


def parse_arguments():
    """Parsea argumentos de l√≠nea de comandos"""
    parser = argparse.ArgumentParser(
        description="Pipeline de generaci√≥n de dataset desde archivos de audio",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos de uso:

# Procesamiento b√°sico
python run_dataset_pipeline.py --input /data --output ./my_dataset

# Con configuraci√≥n personalizada
python run_dataset_pipeline.py --input /data --output ./dataset \\
    --whisper-model medium --workers 8 --batch-size 8

# Solo transcripci√≥n (sin embeddings)
python run_dataset_pipeline.py --input /data --output ./dataset \\
    --skip-embeddings

# Procesamiento r√°pido para desarrollo
python run_dataset_pipeline.py --input /data --output ./dataset \\
    --whisper-model tiny --workers 2
        """
    )
    
    # Directorios principales
    parser.add_argument(
        "--input", "-i",
        required=True,
        help="Directorio con archivos de audio de entrada"
    )
    
    parser.add_argument(
        "--output", "-o", 
        default="./dataset",
        help="Directorio de salida para el dataset (default: ./dataset)"
    )
    
    parser.add_argument(
        "--temp-dir",
        default="./temp_processing",
        help="Directorio temporal para procesamiento (default: ./temp_processing)"
    )
    
    # Configuraci√≥n de audio
    parser.add_argument(
        "--sample-rate",
        type=int,
        default=16000,
        help="Frecuencia de muestreo objetivo en Hz (default: 16000)"
    )
    
    parser.add_argument(
        "--channels",
        type=int,
        choices=[1, 2],
        default=1,
        help="N√∫mero de canales (1=mono, 2=est√©reo) (default: 1)"
    )
    
    # Configuraci√≥n de transcripci√≥n
    parser.add_argument(
        "--whisper-model",
        choices=["tiny", "base", "small", "medium", "large"],
        default="base",
        help="Modelo Whisper a usar (default: base)"
    )
    
    parser.add_argument(
        "--language",
        default="es",
        help="Idioma para transcripci√≥n (default: es)"
    )
    
    parser.add_argument(
        "--batch-size",
        type=int,
        default=4,
        help="Tama√±o de lote para procesamiento (default: 4)"
    )
    
    # Configuraci√≥n de segmentaci√≥n
    parser.add_argument(
        "--segmentation",
        choices=["silence", "time"],
        default="silence",
        help="M√©todo de segmentaci√≥n (default: silence)"
    )
    
    parser.add_argument(
        "--min-silence",
        type=int,
        default=500,
        help="Duraci√≥n m√≠nima de silencio en ms (default: 500)"
    )
    
    parser.add_argument(
        "--silence-thresh",
        type=int,
        default=-40,
        help="Umbral de silencio en dB (default: -40)"
    )
    
    parser.add_argument(
        "--segment-duration",
        type=float,
        default=10.0,
        help="Duraci√≥n de segmento para m√©todo 'time' en segundos (default: 10.0)"
    )
    
    # Configuraci√≥n de embeddings
    parser.add_argument(
        "--text-model",
        default="sentence-transformers/all-MiniLM-L6-v2",
        help="Modelo para embeddings de texto"
    )
    
    parser.add_argument(
    )
    
    parser.add_argument(
        "--skip-embeddings",
        action="store_true",
        help="Omitir generaci√≥n de embeddings (solo transcripci√≥n)"
    )
    
    # Configuraci√≥n de paralelizaci√≥n
    parser.add_argument(
        "--workers",
        type=int,
        default=4,
        help="N√∫mero de workers paralelos (default: 4)"
    )
    
    parser.add_argument(
        "--no-multiprocessing",
        action="store_true",
        default=True,  # Desactivado por defecto
        help="Deshabilitar multiprocesamiento"
    )
    
    # Opciones de salida
    parser.add_argument(
        "--no-intermediate",
        action="store_true",
        help="No guardar archivos intermedios"
    )
    
    parser.add_argument(
        "--compress",
        action="store_true",
        help="Comprimir salida final"
    )
    
    # Opciones de ejecuci√≥n
    parser.add_argument(
        "--resume",
        action="store_true",
        help="Intentar reanudar procesamiento previo"
    )
    
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Mostrar qu√© se har√≠a sin ejecutar"
    )
    
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="Mostrar salida detallada"
    )
    
    # Configuraci√≥n desde archivo
    parser.add_argument(
        "--config-file",
        help="Cargar configuraci√≥n desde archivo JSON"
    )
    
    return parser.parse_args()


def load_config_from_file(config_file: str) -> dict:
    """Carga configuraci√≥n desde archivo JSON"""
    config_path = Path(config_file)
    if not config_path.exists():
        raise FileNotFoundError(f"Archivo de configuraci√≥n no encontrado: {config_file}")
    
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def create_dataset_config(args) -> DatasetConfig:
    """Crea configuraci√≥n del dataset desde argumentos"""
    
    # Cargar configuraci√≥n base del sistema
    system_config = get_config()
    
    # Cargar desde archivo si se especifica
    file_config = {}
    if args.config_file:
        file_config = load_config_from_file(args.config_file)
    
    # Crear configuraci√≥n combinada (prioridad: args > archivo > sistema)
    config = DatasetConfig(
        # Directorios
        input_dir=args.input,
        output_dir=args.output,
        temp_dir=args.temp_dir,
        
        # Audio
        target_format="wav",
        sample_rate=file_config.get("sample_rate", args.sample_rate),
        channels=file_config.get("channels", args.channels),
        
        # Transcripci√≥n
        whisper_model=file_config.get("whisper_model", args.whisper_model),
        language=file_config.get("language", args.language),
        batch_size=file_config.get("batch_size", args.batch_size),
        
        # Segmentaci√≥n
        segmentation_method=file_config.get("segmentation_method", args.segmentation),
        min_silence_len=file_config.get("min_silence_len", args.min_silence),
        silence_thresh=file_config.get("silence_thresh", args.silence_thresh),
        segment_duration=file_config.get("segment_duration", args.segment_duration),
        
        # Embeddings
        text_model=file_config.get("text_model", args.text_model),
        
        # Paralelizaci√≥n
        max_workers=file_config.get("max_workers", args.workers),
        use_multiprocessing=not args.no_multiprocessing,
        
        # Output
        save_intermediate=not args.no_intermediate,
        compress_output=args.compress
    )
    
    return config


def print_config_summary(config: DatasetConfig):
    """Imprime resumen de la configuraci√≥n"""
    logging.info("üîß Configuraci√≥n del Pipeline")
    logging.info("=" * 50)
    logging.info(f"üìÅ Input:  {config.input_dir}")
    logging.info(f"üìÅ Output: {config.output_dir}")
    logging.info(f"üé§ Whisper: {config.whisper_model}")
    logging.info(f"üìù Text Model: {config.text_model}")
    logging.info(f"üìä Segmentaci√≥n: {config.segmentation_method}")
    logging.info(f"üë• Workers: {config.max_workers}")
    logging.info(f"üíæ Intermediate: {config.save_intermediate}")
    logging.info("")


def dry_run_analysis(config: DatasetConfig):
    """Analiza qu√© se har√≠a en un dry run"""
    logging.info("üîç An√°lisis de Dry Run")
    logging.info("=" * 30)
    
    input_path = Path(config.input_dir)
    if not input_path.exists():
        logging.error(f"‚ùå Directorio de entrada no existe: {input_path}")
        return False
    
    # Contar archivos de audio
    audio_extensions = {'.wav', '.mp3', '.flac', '.ogg', '.m4a', '.aac', '.wma', '.opus'}
    audio_files = []
    
    for ext in audio_extensions:
        audio_files.extend(input_path.rglob(f"*{ext}"))
        audio_files.extend(input_path.rglob(f"*{ext.upper()}"))
    
    logging.info(f"üìä Archivos encontrados: {len(audio_files)}")
    
    # Estimar tiempo de procesamiento
    if audio_files:
        logging.info("üìÅ Ejemplos de archivos:")
        for i, file in enumerate(audio_files[:5]):
            logging.info(f"  {i+1}. {file.name}")
        if len(audio_files) > 5:
            logging.info(f"  ... y {len(audio_files) - 5} m√°s")
    
    # Estimar espacio en disco
    total_size = sum(f.stat().st_size for f in audio_files)
    logging.info(f"üíæ Tama√±o total: {total_size / (1024**2):.1f} MB")
    
    # Directorios que se crear√≠an
    logging.info("\nüìÅ Directorios que se crear√°n:")
    dirs = [
        config.output_dir,
        f"{config.output_dir}/converted",
        f"{config.output_dir}/transcriptions",
        f"{config.output_dir}/embeddings",
        f"{config.output_dir}/indices",
        f"{config.output_dir}/final"
    ]
    
    for dir_path in dirs:
        exists = "‚úÖ" if Path(dir_path).exists() else "üìÅ"
        logging.info(f"  {exists} {dir_path}")
    
    return len(audio_files) > 0


def main():    """Funci√≥n principal"""    args = parse_arguments()        logging.info("üéµ Pipeline de Generaci√≥n de Dataset de Audio")    logging.info("=" * 60)    logging.info(f"‚è∞ Inicio: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")    logging.info("")        try:        # Crear configuraci√≥n        config = create_dataset_config(args)                # Mostrar configuraci√≥n        if args.verbose:            print_config_summary(config)                # Dry run si se solicita        if args.dry_run:            success = dry_run_analysis(config)            if success:                logging.info("\n‚úÖ Dry run completado. Todo listo para procesamiento.")                return 0            else:                logging.error("\n‚ùå Dry run fall√≥. Revisa la configuraci√≥n.")                return 1                # Verificar directorio de entrada        if not Path(config.input_dir).exists():            logging.error(f"‚ùå Error: Directorio de entrada no existe: {config.input_dir}")            return 1                # Crear orquestador        orchestrator = DatasetOrchestrator(config)                # Ejecutar pipeline        if args.skip_embeddings:            logging.warning("‚ö†Ô∏è  Modo solo transcripci√≥n - embeddings omitidos")            # TODO: Implementar modo solo transcripci√≥n            logging.error("‚ùå Modo solo transcripci√≥n no implementado a√∫n")            return 1        else:            result = orchestrator.run_full_pipeline()                # Mostrar resultados        if result["success"]:            logging.info(f"\n‚úÖ ¬°Pipeline completado exitosamente!")            logging.info(f"üìä Estad√≠sticas:")            stats = result["stats"]            logging.info(f"  ‚Ä¢ Archivos procesados: {stats['converted_files']}/{stats['total_files']}")            logging.info(f"  ‚Ä¢ Segmentos generados: {stats['total_segments']}")            logging.info(f"  ‚Ä¢ Tiempo total: {stats['processing_time']:.2f} segundos")            logging.info(f"  ‚Ä¢ Archivos fallidos: {stats['failed_files']}")                        logging.info(f"\nüìÅ Dataset creado en: {result['dataset']['dataset_dir']}")            logging.info(f"üìã Manifiesto: {result['dataset']['manifest']}")                        if args.verbose:                logging.info(f"\nüìÑ Archivos generados:")                for key, path in result['dataset'].items():                    if key != 'dataset_dir':                        logging.info(f"  ‚Ä¢ {key}: {path}")                        return 0        else:            logging.error(f"\n‚ùå Pipeline fall√≥: {result['error']}")            logging.info(f"‚è±Ô∏è  Tiempo transcurrido: {result['stats']['processing_time']:.2f} segundos")            return 1                except KeyboardInterrupt:        logging.warning("\n‚ö†Ô∏è  Procesamiento interrumpido por el usuario")        return 1    except Exception as e:        logging.error(f"\n‚ùå Error inesperado: {str(e)}")        if args.verbose:            import traceback            traceback.print_exc()        return 1    finally:        # Limpieza        if 'orchestrator' in locals():            orchestrator.cleanup()


if __name__ == "__main__":
    exit(main())