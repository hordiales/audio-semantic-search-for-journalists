#!/usr/bin/env python3
"""
Test script for MCP server dataset functionality
Tests the new dataset loading and management tools
"""

import asyncio
import json
from pathlib import Path
import sys

CURRENT_FILE = Path(__file__).resolve()
TESTS_ROOT = CURRENT_FILE
while TESTS_ROOT.name != "tests" and TESTS_ROOT.parent != TESTS_ROOT:
    TESTS_ROOT = TESTS_ROOT.parent
if str(TESTS_ROOT) not in sys.path:
    sys.path.insert(0, str(TESTS_ROOT))

from tests.common.path_utils import PROJECT_ROOT, SRC_ROOT, ensure_sys_path

TMP_ROOT = PROJECT_ROOT / "tmp"
for candidate in (CURRENT_FILE.parent, TMP_ROOT, SRC_ROOT):
    ensure_sys_path([candidate])

try:
    from mcp_server import SemanticSearchMCPServer
    MCP_AVAILABLE = True
except ImportError:
    MCP_AVAILABLE = False
    print("Warning: MCP library not available")

async def test_mcp_dataset_tools():
    """Test MCP server dataset tools"""
    if not MCP_AVAILABLE:
        print("âŒ MCP not available, testing core functionality only")
        return await test_core_functionality()  # Test without MCP

    print("ğŸ§ª Testing MCP Server Dataset Tools")
    print("=" * 50)

    # Create server instance
    server = SemanticSearchMCPServer()

    try:
        # Test 1: Initialize system
        print("\n1ï¸âƒ£ Testing system initialization...")
        result = await server._initialize_system({"use_mock": True})
        print("âœ… System initialized")

        # Test 2: Get dataset info
        print("\n2ï¸âƒ£ Testing dataset info...")
        result = await server._get_dataset_info({})
        info = json.loads(result[0].text)
        print(f"ğŸ“Š Available datasets: {len(info.get('available_datasets', {}))}")
        print(f"ğŸ”§ Current mode: {info.get('current_mode')}")

        # Test 3: Load sample data first
        print("\n3ï¸âƒ£ Testing sample data loading...")
        result = await server._load_sample_data({})
        sample_result = json.loads(result[0].text)
        print(f"âœ… Sample data: {sample_result.get('segments_loaded')} segments")

        # Test 4: Try to load real dataset (small subset)
        print("\n4ï¸âƒ£ Testing real dataset loading...")
        result = await server._load_real_dataset({"load_limit": 25})

        if "error" not in result[0].text.lower():
            real_result = json.loads(result[0].text)
            print(f"âœ… Real dataset: {real_result.get('segments_loaded')} segments")
            print(f"ğŸ“ Source: {real_result.get('dataset_source')}")

            # Test sentiment search on real data
            print("\n5ï¸âƒ£ Testing sentiment search on real data...")
            search_result = await server._sentiment_search({
                "sentiment": "positive",
                "top_k": 3
            })

            if "error" not in search_result[0].text.lower():
                search_data = json.loads(search_result[0].text)
                print(f"ğŸ” Found {search_data.get('results_count')} results")
            else:
                print(f"âš ï¸ Search result: {search_result[0].text}")
        else:
            print(f"âš ï¸ Real dataset loading: {result[0].text}")

        # Test 5: Switch dataset modes
        print("\n6ï¸âƒ£ Testing dataset mode switching...")
        switch_result = await server._switch_dataset_mode({"mode": "sample"})
        if "error" not in switch_result[0].text.lower():
            switch_data = json.loads(switch_result[0].text)
            print(f"ğŸ”„ Switched to: {switch_data.get('mode')}")
        else:
            print(f"âš ï¸ Mode switch: {switch_result[0].text}")

        print("\nğŸ‰ MCP dataset tools tests completed!")
        return True

    except Exception as e:
        print(f"âŒ Test failed: {e}")
        return False

async def test_core_functionality():
    """Test core functionality without MCP"""
    print("ğŸ§ª Testing Core Dataset Functionality (No MCP)")
    print("=" * 50)

    try:
        # Import and test core components
        from semantic_search import SemanticSearchEngine
        from sentiment_analysis import SentimentAnalyzer

        print("\n1ï¸âƒ£ Testing semantic search engine...")
        config = {
            'whisper_model': 'base',
            'text_embedding_model': 'sentence-transformers/all-MiniLM-L6-v2',
            'use_mock_audio': True,
            'use_mock_sentiment': True,
            'index_type': 'cosine',
            'top_k_results': 5
        }

        engine = SemanticSearchEngine(config)
        print("âœ… Search engine created")

        # Test dataset detection
        print("\n2ï¸âƒ£ Testing dataset detection...")
        from pathlib import Path

        dataset_dir = Path("./dataset")
        if dataset_dir.exists():
            metadata_files = list(dataset_dir.glob("**/dataset_metadata.csv"))
            if not metadata_files:
                metadata_files = list(dataset_dir.glob("**/segments_metadata.csv"))

            if metadata_files:
                import pandas as pd
                df = pd.read_csv(metadata_files[0])
                print(f"âœ… Found dataset: {len(df):,} segments")
                print(f"ğŸ“Š Languages: {df.get('language', pd.Series()).value_counts().head(3).to_dict()}")
            else:
                print("âš ï¸ No metadata files found")
        else:
            print("âš ï¸ No dataset directory found")

        print("\n3ï¸âƒ£ Testing sentiment analyzer...")
        analyzer = SentimentAnalyzer()
        test_text = "Â¡QuÃ© alegrÃ­a! Excelente noticia para todos."
        sentiment_scores = analyzer.analyze_text(test_text)
        dominant = max(sentiment_scores, key=sentiment_scores.get)
        print(f"âœ… Sentiment analysis: {dominant} ({sentiment_scores[dominant]:.3f})")

        print("\nğŸ‰ Core functionality tests completed!")
        return True

    except Exception as e:
        print(f"âŒ Core functionality test failed: {e}")
        return False

def test_mcp_tools_list():
    """Test that all MCP tools are properly registered"""
    if not MCP_AVAILABLE:
        print("âŒ MCP not available, skipping tools test")
        return

    print("\nğŸ”§ Testing MCP Tools Registration")
    print("=" * 40)

    server = SemanticSearchMCPServer()

    # Check that server has all expected tools
    expected_tools = [
        "initialize_search_system",
        "semantic_search",
        "sentiment_search",
        "get_sentiment_distribution",
        "get_available_sentiments",
        "analyze_text_sentiment",
        "load_sample_data",
        "get_system_stats",
        "find_emotional_content",
        "load_real_dataset",       # New tool
        "get_dataset_info",        # New tool
        "switch_dataset_mode"      # New tool
    ]

    print(f"Expected tools: {len(expected_tools)}")
    for tool in expected_tools:
        print(f"  âœ… {tool}")

    print("\nğŸ’¡ Use these tools in your LLM to access sentiment search functionality!")

async def main():
    """Main test function"""
    print("ğŸ­ MCP Server Dataset Integration Tests")
    print("=" * 60)

    # Test tools registration
    test_mcp_tools_list()

    # Test dataset functionality
    await test_mcp_dataset_tools()

    print("\n" + "=" * 60)
    print("ğŸ“– Usage Examples:")
    print()
    print("For LLMs using MCP:")
    print('  {"name": "get_dataset_info", "arguments": {}}')
    print('  {"name": "load_real_dataset", "arguments": {"load_limit": 100}}')
    print('  {"name": "sentiment_search", "arguments": {"sentiment": "happy", "top_k": 5}}')
    print('  {"name": "switch_dataset_mode", "arguments": {"mode": "real"}}')
    print()
    print("For CLI:")
    print("  python cli_sentiment_search.py --dataset-info")
    print("  python cli_sentiment_search.py --load-real --load-limit 100 --sentiment feliz")
    print()
    print("ğŸš€ Ready for LLM integration!")

if __name__ == "__main__":
    asyncio.run(main())
